Brett from Design Joy is this one-man designer who's making millions of dollars a year, but that's not the most interesting part about him. The most interesting part is he's using AI to generate some of the most beautiful designs I have ever seen. And Brett, by the end of this episode, what will people get out of it?

So I think people will be pretty shocked by the simple path it is to arrive at beautifully generated graphics, no matter what you're doing. There is no kind of magic behind the scenes all that much. These tools are really powerful.

Long story short, it's super easy, and I think people will be surprised by that. Hey you, you want $5,000 to go build out your startup idea? Because I'm giving away $5,000.

So it's a giveaway, we're doing it. The way to enter, super simple and free. So let's go ahead and do it right now.

Step one is like this video. So go ahead and go find that little like button. Boom.

Like. Done. Second thing, comment on this video.

Go to the comment section, scroll down. Oh, there it is. Answer, what startup would you want to build with the $5,000?

Don't know the answer to that? That's okay. Even what space do you want to go build in?

Dating app, fintech app, you name it. And then number three, you're going to want to go to ideabrowser.com. I've pinned it.

It's a pinned comment. So you can go to that link. Hit it.

Open it up. And you're going to see this website that gives away a free startup idea based on a trend. And every single day.

So we're literally dishing out free startup ideas. This is a startup I co-founded. And go and sign up to it for free.

And hopefully it'll get your creative juices flowing. I want to give a special shout out to Bolt.new for poning up the $5,000 to give to you. They're putting their money where their mouth is.

A lot of you know Bolt.new because I've used the product a lot. And, you know, but for people who don't know, it's an AI coding tool where you write a few words and software magically comes out of it. It's a beautiful thing.

Check it out, Bolt.new. And thank you for supporting the Startup Ideas podcast. And for the last giveaway, we're going to announce who won in a few weeks.

I'm actually hoping I can bring them on to the podcast and film their reaction. So we'll see. Hopefully they want to come on.

But excited to announce who won the last $5,000 giveaway. And when you say easy, you know, you're a super talented designer. So I'm someone who's, I wouldn't call myself a designer.

Will someone like me be able to create insane value out of these tools? That's the goal, right? And we'll go through this.

There's definitely levels to this AI generation thing. Most of the content that I put out there is not geared directly towards designers. It's geared towards, you know, anybody with a mid-journey subscription, ChatGPT subscription.

So you really don't have to have any prior design knowledge at all. Having good taste definitely helps. But aside from that, there's really no skill issue here at all if you're a non-creative.

All right. Let's get into it. Yeah.

I mean, so there's a lot of different realms with this AI, generative AI sort of phase that we're in right now. You know, you have image generation, you have video generation, you have all kinds of different things. So we'll start with the top.

We'll start with like the easiest form if you want to kind of get your feet wet with this AI creation thing that we're in right now. Not sponsored by any of these tools. These are just tools that I use in different sort of circumstances.

So we'll start with like the easiest. Then we'll go into like the realm that I play the most in. So like if you just wanted to, for example, if we're in here, essentially like Higgs field is one of those.

Again, you have no experience at all. You want to just see how this works. So Higgs field is basically all these templates that you can use, right?

So we can try one out if you want to. Can we do that real quick? Yeah.

It's a pretty quick thing. So one of the hardest parts about AI is understanding how to talk to the AI and what to tell it to actually do. I mean, if we're doing an ad, for example, when it comes to video, most of us don't talk like a director.

We don't know what dolly in, dolly out, all that typically means. So Higgs field is like, it's coming down to our level and giving us these sort of preset actions, so to speak, and effects. And so we can just take, let's just take this for example here.

And I'll show you how well this works. So let's go, let's see, hopefully this follows me. So let's do like a liquid death can.

Do you drink liquid death? You ever tried it? I've tried it.

I like my water out of a glass bottle, you know? I hear you. That's fair.

I've never tried it, so I'm not neither a fan nor a foe. So we'll just add this in. So let's say you have a drink company or if you have anything, you know, really anything, we'll see how actually well this works.

So literally all I did was I picked a preset, right? Uploaded a picture of a product. And let's just hit generate and see what happens.

So hopefully what it should do, well, actually, we've done this before. So we can, we don't have to wait for this. So what it should do, I think there's one down here that was interesting.

Yeah. So it actually takes into consideration the can and the branding. It could swap the model out.

And then when you play this, you know, it's like. Oh my God. It's perfect.

You know, it maintains the text on the can. That's one of these things where the text has always been kind of the problem child of AI generation because it never quite got it right. Well, we're past that point now.

It gets text right. I wasn't into liquid death before, but after watching that video, I'm into liquid death. There you go.

There you go. Yeah. I mean, it is quick, right?

I mean, the hardest part about AI generation, just waiting for the image to generate. But with this tool, right, you don't have to prompt it. It has all these presets, right?

So this is, and you have, if you click over here, right, this is where you could prompt it if you wanted to do something very specific. Upload your reference photo. And then if you click into here, you have, again, all of these different effects, right?

If I wanted to turn something into metal, if I wanted to just sort of call out different basic camera controls on certain things, and then it just does it really quick. No, no. This is, again, like a good early entry into AI generation.

Now, do I do a lot of this? Not really. This is like, it's fun to show.

And again, if you have a product, it's a great way to create some cool, like ads for Instagram and stuff like that. But the real fun is over in the ChatGPT mid-journey side of things. So ChatGPT, again, all of these, we'll go to mid-journey for a moment.

Mid-journey is where we generate these images, right? It's not video. We're going to generate, if you're going to do video, this is where you oftentimes start because you need a base initial, a kind of reference image to begin with.

And so what's your, Greg, have you used mid-journey quite a bit or? Yeah. I would say I've used a decent amount.

A decent amount. Yeah. So the issue right now is you have all these tools and they pop up all the time, right?

We have Kling, we have Krea, we have all these different, we have Visual Electric, Flora. There's a hundred of them out there. It's easy to get distracted and figure out, you know, should I be trying all these tools?

I pretty much stick to like the top three or four of them. I keep a pulse on all the other ones, but really like mid-journey, mid-journey and ChappieT are the two that I use by far the most. And I use them together in a really like special way.

So mid-journey is like phenomenal at styling. You know, if you want to, like this morning, for example, I'm doing branding for a work called Leisure Labs. You know, and so I'm generating these sort of like Kodak vintage aerial photos of a golf course, for example.

Then I wanted to supply a different sort of brand direction for like a surfer or something like that, right? Kind of on that leisure side of things. Did some other stuff around creating some buildings and stuff.

But it gets the styling as far as like the artistic styling is part of none than any other tool out there. So this is where I go if I want to create something really artistic. ChatGPT, on the other hand, is where I go if I want something very specific.

So I'll take a photo here, for example. And mid-journey can sometimes get the image right if I want to add in a person to this photo that's like teeing off or something. But you can tell if I were to zoom in on this, it kind of, I mean, kind of look at that shadow, right?

Kind of weird. And in an ideal world, you take this into ChatGPT and say, hey, take this photo, just insert an overhead shot of a golfer. And it would get it mostly realistic, way more realistic than mid-journey.

So using them, knowing how to use them together is definitely key. But these systems are only as good as what prompt you give them or what reference image you provide. So for those that haven't used mid-journey before, it's a very simple system.

We don't need to spend 30 minutes undergoing how it works. But you essentially have a prompt that you can tell it what you want to do. And then you're basically going to be using image prompts and style references.

So image prompts, for those that don't know, is if I insert a photo into here of the surfer, it's going to, the next image it's going to generate might have a person in it, might have a surfboard in it, might have, you know, sort of like greenery in it. If I insert a style reference, for example, this one right here, it's whatever image I generate is going to have those colors, the same shadows, highlights, depth of field, that sort of thing. So you use those together in really cool ways.

And it's fun to like mix styles. If I wanted to upload like this orange style with this green style, you can get some really cool generations that are quite a bit, quite surprising. But again, they're only as good as the prompt that you provide.

And so that's where ChatGPT comes in. So it used to be that that prompting was a skill. And it was before GPT got as good as it was.

Knowing how to describe these things that you wanted was like, it almost took, you know, like author level skills when it come, when it came to writing and describing and kind of visualizing and imagining these things. But nowadays, prompting is not a skill. It's like people in the AI community like to gatekeep it.

You know, they'll say, here's the prompt that I wrote. And people are like, how do you think of those things? Or a lot of times they don't even share the prompt.

But ChatGPT is very good at giving prompts. So we can see an example here. So if I'm going to pull up, like for example, I was doing, I want to do some like cowboy, cowboy art, right?

So I started with a simple thing. I want to write some image prompts to generate a zoomed in photo of a cowboy on the back of a horse riding the reins. They're holding the reins.

The photo should be zoomed in on the hands and reins. So it basically gives me, you know, a few options for a prompt. And it does it in a really well done way where I could never write this stuff.

I could never think of it. And if we go over here to ChatGPT, we can actually see what these things created. Somebody scroll down here for a moment.

So I used a style image, a style reference of this image right here. This was something that I created in MidJourney. Uploaded it as a style reference.

This didn't upload an image prompt because I, quite frankly, I have a prompt. I don't really need that all that much. So I put it in here and got several, several like really solid options.

And this is sort of in the realm of perplexity branding for those that are fans of it, huge fan of myself. And then, you know, I basically just talked back to it. I said, now I want one zoomed in on a cowboy.

And it gave me some and I was like, ah, that's not what I wanted. I meant I want it zoomed in on the cowboy's hat. Right.

So boom, got this like amazing image. And it's, it's right in line with this. And I kept that going, you know, I was like, now I want one zoomed in on the cat, on the, on the horse's face.

Boom, done. And then, you know, one that was zoomed out, showing some mountains in the environment. And all I'm saying is mountains in the same environment.

And it's like adding in all of this extra like rich detail that really makes the image what it is. So I'm just over here. And then you could say like, you could even tell JetTBT, say, hey, I want to create a collection of these as posters.

Give me some different scenes that tie back to the, to the same, you know, initial prompt, but have different elements in different environments. And it'll just dream up all these collections. You don't have to say like a zoomed in photo of the horse, a zoomed in photo of this or whatever.

You can let it kind of dream and imagine for you, which is really cool. So this is the starting point for really good generated, you know, AI art is actually constructing a good prompt. And then you take that into here, you know, you plug in a style image and boom, you're, you know, you're done at this point if you want to do that.

And you can see I've done this, you know, I've been doing this with different worlds. And this is my latest sort of tutorial is on these sort of like, you know, isometric 3d, you know, worlds that we bring into runway and add motion to them, which we can go through, but it's really not that complex. You have to basically have a very basic idea of what you want.

Prompt that in chat CPT, say, Hey, make me a prompt around this idea or make me several and take those and just start plugging in the mid journey, find a style that you want. Like Pinterest is phenomenal for this. That's all I use to generate, you know, stylistic directions.

I'll come on that. It may not have anything related to what I want to do, but it may be like the right style, the right, like 3d art or the right kind of like feeling and vibe. And I upload as a style image, style reference, plugging my prompt.

And you just kind of just like, at that point, it's just fun to sit back and see what, what's created, you know? But yeah, that's, that's sort of like, that's the, the second tier of, of AI generation is using chat CPT and mid journey together in that way. And then of course you can take these and throw them out.

Throw them into runway and add motion to them. You can bring them into Photoshop and do generator to fill. You can, you can do all kinds of things.

You can throw them into mag, Magnific, which is like an upscaler to really get all these like super rich details, um, which I've done in several of my tutorials. So you, then you start kind of leveling all these tools on and that's where you get this really dope stuff that is, you know, hard to replicate unless you know how to, how to use them in tandem with each other. Um, I mean, even, even this, so the stuff that I'm seeing on the screen, and I've seen some of this on your ex, you know, I think a lot of people saw these beautiful images and are like bookmark and like, but I can never do that because Brett is a designer.

He's like been studying this for years. He's a practitioner. He's made millions of dollars, you know, doing design work.

Therefore, yeah, I'll see you later tutorial, AKA bookmark. But deep down, I think a lot of people are like, I can never do it. I'd be happy to show you.

We can do one in like, we can do one of these scenes, for example, from scratch and, and, you know, five to six minutes. It's not hard, right? Like going through the process of like, you can see this, for example, right?

This beautiful image here. All I did was I went on Pinterest. I found a picture of a cabin, right?

Which was, let's see if this is, loads up. Of course, it's not going to load. Ah, right here.

Boom. Yeah. Found a picture of a cabin.

This was not AI generated. This was just simply pulled from a Pinterest, a Pinterest search. Had a reference image here, which was this one here, a style image that I have saved.

I keep these like in folders in my, in my computer. So I have all these different styles that I can just reference back and forth. And so, yeah, it's going to create this cabin, with the style of these mountains.

And then you can see where, you know, pulling in this color here, but then this, this sort of object is, gets placed here with this simple, very simple prompt. And then you go over to runway, you upload this picture, you give it a prompt, which you create with chat, chat, you go to chat, you say, Hey, here's the image that I want to turn into a video. Give me a prompt that would tell runway what, what, what, like what exactly to move.

And it'll come back and it'll give you, yeah, put soft ripples in the water, have the smoke coming, have the trees blowing softly in the wind, but it's like, tell it to you very eloquently and like sophisticated. And then you just press generate and then you sit back, wait for it to generate and boom, like five minutes later, you have a beautiful, a beautiful video. Then you can even take that further.

You can go over to cling, you know, cling is another image to video tool that allows start and end frame, which means that you can loop it. So the video will start and end with the same frame and cling will just fill in the in between so that if you had like a, an icon that you wanted to put on your site and you wanted to kind of endlessly loop or it wasn't this harsh reset, you just set that start frame and end frame to the same image and it just infinitely loops. And then once that's generated, then it has a little button that says AI sound, you know, take into context the video and give you sound options that are AI generated.

So you can, I mean, you can go and then if you wanted to write these, these, these prompt tools are limited to about 10 seconds per video. You can go to the end video, right click on your, your computer, save the last frame as an image, upload that as the next video. So the, the next video will start at the last frame of your last video and have a continuous shot for as long as you want.

And then stitch them together with a, with a simple video editing tool that you don't have to have really any experience doing. You're just dragging clips onto a timeline and exporting. So it's not, it's not really that, it's not really that complicated when you, when you look at it this way.

Could we look at some of the, the more complex runways or, you know? Yeah. Do you want to, should we like just for the sake of this, just do one of these?

Yeah. So let's do, let's pick an image here. Which one do we like?

Like, I like this one. Oh yeah. This one's cool.

So what I would do, I could probably describe the movement cause I've done this a hundred times creating a, creating a tutorial. Right. Um, but we're just going to throw this into here and we're going to tell it, we don't have to be, we don't have to be sophisticated in the way we talk to chat GPT.

It can understand very little and expand upon it. So I'm going to use runway to add motion to this image. Give me a prompt.

Okay. So it's going to understand, it's not even just going to understand it. Well, it's going to understand what you want to do, but it's even going to understand the tool that you're going to use.

So that it writes it a certain way. Cause if I were to say like, I want to use this up at, put up at mid journey for something, it's going to give you like the style parameters and all these sorts of tags at the end. But since it's runway, we just need very kind of a text format.

So we'll head over to runway. And this is just one of many, many of these tools, cling, krea, all of them do it. Runway is, is certainly on the upper echelon of like quality.

So we'll just upload a, we'll upload an asset here that we have already generated before. Let that upload. And then, so that's our image.

We're going to just paste the prompt in here. Let me read, read through this real quick, just to make sure that software is okay. Keep that, keep the camera completely still for a piece.

So you'd even get, it even understands that. So there's not this, all this movement around. And of course you could tweak all this, right?

Then we're gonna have the aspect ratio just be square. We'll do 10 seconds. Like I said, it's generally five to 10 seconds.

We'll let that, we'll let that run. Why did you choose square versus another format? Well, so I'm typically sharing this on X.

I like portrait media for the most, but when you're sharing a video on X, it'll add black borders to the side of it. I don't like that. I hate it.

Kind of ruins the aesthetic for me. So square is the, square is the best. Now, if you wanted to share something super cinematic, you do like 16 by nine, but I like square cause you, it's, it's bigger on your screen.

It catches, it's going to catch your eye far more. And one other thing I'll say about all this, and this goes for chat to PT, not chat to PT as much. It usually nails things.

Mid journey and runway and all these tools. They're far from perfect. You know, I've done, for example, I was trying to do a 3d logo, rotate like on a, on an axis and it like got halfway and then just some cartoon character popped out of it.

And I'm like, what the heck, where did that come from? So there, they could be a little finicky. So you have to, you have to kind of understand what it's going to be good at and what it's, what it might do some weird things and, and just adjust your prompts accordingly.

So we'll do this. It might nail it, but it might also have like a weird zoom in on it. And so we'll have to readjust things.

We won't do this for the video, but there might be some weird artifacts or something like that, that you, that you notice and you just have to kind of redo it, reprompt it if you need to and kind of keep trying. But, and while this is uploading, I'm curious your perspective on this. So this podcast is called the startup ideas podcast.

It's generally people who want to build startup ideas and, and quit their job or do a side hustle or something like that. What does this whole world of, you know, AI designing or vibe designing enable for, you know, for these people? And what are some opportunities that you can think of that you think will, will be very lucrative?

Yeah. I mean, there's, there's what's capable today, which is again, like a lot of what's being shared out there is, is really more on just like the fun creative side, kind of just, you know, testing these tools out, generating things that aren't quite used every day in the actual design world, more, more than just like a Twitter post, you know, sharing a tutorial. But I think the biggest opportunity right now for creatives is, is really on the branding side.

You know, there, the, the web design side hasn't really had its day in AI quite yet. It's on its way with tools like bolt and level blinds, but the output's pretty mediocre, right? Branding is, you know, it is amazing.

So if I, if for example, what I can do for you, Greg, if, if you wanted to hire me to design like a leisure, you know, a leisure brand, like I was describing, right? I can go into mid journey over here. I can, as your designer or even you, you know, once you, once you find one asset that you really like, you can go into mid journey and actually set up a mood board.

Have you ever done this before or seen this before? No. Yeah.

So you can set up a mood board, right? And I set up a mood board for these, for these cowboy images. Now, anything that I want to do at this point in time, I can use this, this code as a prompt, and it's going to reference back to all of this here.

And so it gives you the ability to basically create content. That's, that's, that, that's relate, that relates to one another's continuity between the content. And it's, it's a, what's the, what's the word I'm looking for?

Consistent. Right. Um, so I could give you the, I could give this to you and then you could basically, if you, if you have, you know, this is a background or whatever for social media posts or whatever it is, you have the ability to then begin to kind of replicate that at very fast paces.

And it's all going to be kind of cohesive. Um, there's little things like it's not good at logo design right now. You can't really like generate the entire brand using it.

It's, it's not, text isn't perfect. Vect, it doesn't do vector art, you know, things like that. So you still need a designer for some of those pieces, but once those pieces are set, the ability for you to take those references and continue to build new additional creatives, um, off of it is really, really where the opportunity is today.

I think that'll get even crazier as times go on, especially with the website side of things and like that sort of thing. But branding is really the biggest, the biggest leverage point at this point, when it comes to AI and the ability to just generate consistent assets, you know, at a very quick pace. Um, yeah, that's that, you know, obviously outside of that chat GPT and stuff can be used for all kinds of things when it comes to startups, but the actual design piece that that's really where that's really where the majority of the, of the opportunity is at this point in time.

Let's go back to this and see if it did it. So we'll play this and hope, hopefully we cross our fingers and it just nails it. Put that in a museum.

Right. And then what's crazy, okay, we can, we can sit down here and we can say upscale to 4k, and we just click it and it just does it. You know, now we have a 4k, a 4k video.

And then what's crazy is you can, you can take this, I can right click on this and save a video frame. I can bring this back over here to here and say, hey, runway, you know, or, or chat GPT or, or mid journey, like pretend as if you're a, a real estate photographer and I need different, different angles of this building shot for, for a listing or a magazine or something like that. And it can get into that role and, and take this reference and, and take different shots of it.

Then you could throw those in the runway, add the same motion. We just did stitch them together in one video. And then you have this amazing, you know, multi-frame, multi-scene, scene video very quickly.

So it's pretty, it's pretty, it's pretty amazing. I would imagine the use case for a lot of these videos is going to be ads. Yes.

Um, how would you, if I wanted to put text on top of these videos, is that possible? Yeah. So text on top.

So you, it does require, there's certain things where you want to branch off, right? Like you could tell runway to do that. It may get it, but if it doesn't, it's slightly off.

You can't just like use your mouse pointer to like move it. Right. It's, it's embedded in the video.

So this is where I would, I would say this video, use a very user friendly, um, video platform like cap cut, where you're just going to drag this in and then drag a text layer on top and you're done. You can position average. You don't have to have any video experience at all to do that.

Very simple takes, you know, five seconds. So that's where there are certain points where you do want to use traditional tools to get, to get those things quite right. Um, but again, like Chad, TBT does a good job of that, but Chad, we didn't, doesn't do video really.

They have Sora, but it's really poor output. But yeah, just like I was doing stuff this morning for an e-commerce shop and they have their products on set on these like cool background images and stuff. And so I was just generating all kinds of psychedelic weird, like, like background images.

Um, yeah, it's, like, it's a person's dream, but it's definitely fun. Even if you're a non-creative to be able to just generate something as beautiful as this. Like you could never have done anything remotely close to this.

I'm a creative and I could have never done anything remotely close to this, um, for the rest of my career, most likely, but now I can do it in five minutes. Um, Brett, this has been eye opening. Um, I'm getting my hands dirty literally right after this.

Um, thank you for coming on. I'm going to include, uh, where to find Brett and follow his tutorials in the show notes so people can go and follow him there. Brett, is there anything, uh, you want to leave people with or say?

Yeah, no, I mean, I, like I said, like what you're going to do, get your hands dirty, utilize chat to be too. Uh, and, and know which ones are good at different things, but yeah, mostly just get your hands dirty. Don't, don't stress about there being too many tools.

Like pick a couple that you're, that you like, stick with them, learn how they work. Um, yeah, you can do, is the coolest part about AI and something that a lot of people want to say or admit, you know, there's a level of gatekeep, keeping this around this sort of stuff. And, and my goal is just to kind of break down those barriers and show pretty much anybody can do this sort of stuff.

So, yeah, that's it. Well, I appreciate that. Like, this is sauce as far as I'm concerned.

This is like good sauce that you're sharing and, and you demystify this for thousands of people watching and it's going to make a difference in their lives 100%. So thank you for sharing your knowledge and being here and being so generous. Of course.

My pleasure. Thanks for having me on. Brett from design joy.

Peace. Peace. Peace peace peace peace peace and peace peace peace peace peace peace peace peace peace peace peace