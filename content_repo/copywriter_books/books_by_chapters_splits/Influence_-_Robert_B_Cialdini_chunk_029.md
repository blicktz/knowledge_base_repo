#### I know that whenever I encounter or learn of an influence attempt of this sort, it sets off in me a kind of alarm with a clear directive: Attention! Attention! May be bad social proof in this situation. Temporarily disconnect

-----

#### autopilot. It’s easy to do. We need only make a conscious decision to be alert to evidence of biased social evidence. We can cruise along until the exploiters’ deception is spotted, at which time we can pounce.
 And we should pounce with a vengeance. I am speaking of more than simply ignoring the misinformation, although this defensive tactic is certainly called for. I am speaking of aggressive counterattack. Whenever possible, we ought to sting those responsible for the rigging of social evidence. We should purchase no products associated with biased “unrehearsed interview” commercials or artificial waiting lines. Moreover, each manufacturer of the items should receive a forceful comment on its website explaining our response and recommending that they discontinue use of the advertising or marketing agency that produced so deceptive a presentation of their product.
 Although we don’t always want to trust the actions of others to direct our conduct—especially in situations important enough to warrant our personal investigation of the pros and cons, or ones in which we are experts —we do want to be able to count on others’ behavior as a source of valid information in a wide range of settings. If we find in such settings we cannot trust the information to be valid because someone has tampered with the evidence, we ought to be ready to strike back. In such instances, I personally feel driven by more than an aversion to being duped. I bristle at the thought of being pushed into an unacceptable corner by those who would use one of my hedges against the decisional overload of modern life against me. And I get a genuine sense of righteousness by lashing out when they try. If you are like me—and many others like me—so should you.

### Looking Up

#### In addition to the times when social proof is deliberately faked, there is another time when the principle will regularly steer us wrong. In such an instance, an innocent, natural error will produce snowballing social proof that pushes us to an incorrect decision. The pluralistic-ignorance phenomenon, in which everyone at an emergency sees no cause for alarm, is one example of this process.
 The best illustration I know, however, comes from Singapore, where a few years ago, for no good reason, customers of a local bank began drawing out their money in a frenzy. The run on this respected bank remained a

-----

#### mystery until much later, when researchers interviewing participants discovered its peculiar cause: An unexpected bus strike had created an abnormally large crowd waiting at the bus stop in front of the bank that day. Mistaking the gathering for a crush of customers poised to withdraw their funds from a failing bank, passersby panicked and got in line to withdraw their deposits, which led more passersby to do the same. Soon after opening its doors, the bank was forced to close to prevent a complete crash.
 This account provides certain insights into the way we respond to social proof. First, we seem to assume that if a lot of people are doing the same thing, they must know something we don’t. Especially when we are uncertain, we are willing to place an enormous amount of trust in the collective knowledge of the crowd. Second, quite frequently the crowd is mistaken because its members are not acting on the basis of any superior information but are reacting, themselves, to the principle of social proof.
 There is a lesson here: an autopilot device, like social proof, should never be trusted fully; even when no saboteur has slipped misinformation into the mechanism, it can sometimes go haywire by itself. We need to check the machine from time to time to be sure that it hasn’t worked itself out of sync with the other sources of evidence in the situation—the objective facts, our prior experiences, and our own judgments.
 Fortunately, this precaution requires neither much effort nor much time. A quick glance around is all that is needed. And this little precaution is well worth it. The consequences of single-minded reliance on social evidence can be frightening. For instance, a masterful analysis by aviation-safety researchers has uncovered an explanation for the misguided decisions of many pilots who crashed while attempting to land planes after weather conditions had become dangerous. The pilots hadn’t focused sufficiently on the mounting physical evidence for aborting a landing. Rather, they had focused too much on the mounting social evidence for attempting one—the fact that each in a line of prior pilots had landed safely.
 Certainly, a flier following a line of others would be wise to glance occasionally at the instrument panel and weather conditions outside the window. In the same way, we need to look up and around periodically whenever we are locked into the evidence of the crowd. Without this simple safeguard against misguided social proof, our outcomes might well run parallel to those of the unfortunate pilots and the Singapore bank: crash.[16]

-----

**_READER’S REPORT 4.6_**

#### From a former racetrack employee

I became aware of one method of faking social evidence to one’s advantage while working
at a racetrack. In order to lower the odds and make more money, some bettors are able to
sway the public to bet on bad horses.

Odds at a racetrack are based on where the money is being bet. The more money on a
horse, the better the odds. Many people who play the horses have surprisingly little
knowledge of racing or betting strategy. Thus, especially when they don’t know much
about the horses in a particular race, a lot of times they’ll simply bet the favorite. Because
tote boards display up-to-the-minute odds, the public can always tell who the current
favorite is. The system that a high roller can use to alter the odds is actually quite simple.
The guy has in mind a horse he feels has a good chance of winning. Next he chooses a
horse that has long odds (say, 15 to 1) and doesn’t have a realistic chance to win. The
minute the mutuel windows open, the guy puts down $100 on the inferior horse, creating
an instant favorite whose odds on the board drop to about 2 to 1.

Now the elements of social proof begin to work. People who are uncertain of how to
bet the race look to the tote board to see which horse the early bettors have decided is a
favorite, and they follow. A snowballing effect now occurs as other people continue to bet
the favorite. At this point, the high roller can go back to the window and bet heavily on his
true favorite, which will have better odds now because the “new favorite” has been pushed
down the board. If the guy wins, the initial $100 investment will have been worth it many
times over.

I’ve seen this happen myself. I remember one time a person put down $100 on a prerace 10 to 1 shot, making it the early favorite. The rumors started circulating around the
track—the early bettors knew something. Next thing you know, everyone (myself included)
was betting on this horse. It ended up running last and had a bad leg. Many people lost a lot
of money. Somebody came out ahead, though. We’ll never know who. But he is the one
with all the money. He understood the theory of social proof.

**Author’s note: Once again we can see that social proof is most telling for those who**
feel unfamiliar or unsure in a specific situation and who, consequently, must look outside
of themselves for evidence of how best to behave there. In this case, we can see how
profiteers will take advantage of the tendency.

## SUMMARY

#### The principle of social proof states that one important means people use to decide what to believe or how to act in a situation is to examine

-----

#### what others are believing or doing there. Powerful such effects have been found among both children and adults and in such diverse activities as purchase decisions, charity donations, and phobia remission. The principle of social proof can be used to stimulate a person’s compliance with a request by communicating that many other individuals (the more, the better) are or have been complying with it. Therefore, simply pointing to the popularity of an item elevates its popularity.

 Social proof is most influential under three conditions. The first is uncertainty. When people are unsure, when the situation is ambiguous, they are more likely to attend to the actions of others and to accept those actions as correct. In ambiguous situations, for instance, the decisions of bystanders to offer emergency aid are much more influenced by the actions of other bystanders than when the situation is a clear-cut emergency.

 A second condition under which social proof is most influential involves “the many”: people are more inclined to follow the lead of others in proportion to the others’ number. When we see multiple others performing an action, we become willing to follow because the action appears to be more (1) correct/valid, (2) feasible, and (3) socially acceptable.

 The third optimizing condition for social-proof information is similarity. People conform to the beliefs and actions of comparable others, especially their peers—a phenomenon we can call peer-suasion. Evidence for the powerful influence of the actions of similar others can be seen in suicide statistics compiled by sociologist David Phillips. The statistics indicate that after highly publicized suicide stories, other troubled individuals, who are similar to the suicide-story victim, decide to kill themselves. An analysis of the mass-suicide incident at Jonestown, Guyana, suggests the group’s leader, Reverend Jim Jones, used both of the factors of uncertainty and similarity to induce a herdlike suicide response from the majority of the Jonestown population.

-----

#### The social-proof BIG MISTAKE many communicators make is to decry the frequency with which an unwanted behavior (drinking and driving, teen suicide, etc.) is performed, as a way to stop it. However, they don’t recognize that within the lament “Look at all the people who are doing this undesirable thing” lurks the undercutting message “Look at all the people who are doing it,” which can make it worse via the principle of social proof.

 When communicators are not able to use existing social proof because their idea, cause, or product does not have widespread support, they may be able to harness the power of future social proof by honestly describing trending support, which audiences expect to continue.

 Recommendations to reduce our susceptibility to faulty social proof include cultivating a sensitivity to counterfeit evidence of what similar others are doing and recognizing that the actions of similar others should not form the sole basis for our decisions.



-----

#### Follow an expert.

#### Chapter 5
# Authority

### Directed Deference

**—Virgil**

#### Not long ago, a South Korean journalist asked me, “Why is behavioral science so hot now?” There are several reasons, but one involves the operation of behavioral-science research divisions in government, business, legal, medical, educational, and nonprofit organizations around the globe. At last count, about six hundred such research units had taken root in less than ten years—each dedicated to testing how behavioral-science principles could be used to solve various real-world problems. The first of these, the British government’s Behavioural Insights Team (BIT), has been particularly productive.
 For instance, to examine how to increase giving to deserving causes, especially among individuals whose financial resources allowed for substantial contributions, BIT researchers compared the success of techniques to motivate investment bankers to donate a full day’s salary to charity. At the London offices of a large international bank, bankers received a request to provide such a donation in support of the bank’s fundraising campaign for a pair of charities (Help a Capital Child and Meningitis Research UK). One set of bankers, in the control group, got the request in a standard letter asking for the financial commitment; it produced 5 percent compliance. A second set got a visit from an admired celebrity who endorsed the program; this liking-based tactic bumped up compliance to 7 percent. A third sample encountered a reciprocity-based appeal; upon entering the building, they were approached by a volunteer who first gave each a packet of sweets and then asked them to participate in the program,

-----

#### which boosted compliance to 11 percent. A fourth group received an appeal that incorporated the principle of authority in the form of a letter from their CEO extolling the importance of the program to the bank as well as the value of the selected charities to society; it generated 12 percent compliance. A final sample got a blend of the reciprocity and authority influence principles—the gift of sweets from a volunteer plus the CEO’s personalized letter. Compliance soared to 17 percent.
 It’s evident that the CEO’s letter, both singly and together with another principle of influence, had significant effects on the decision to donate. That was so because the source of the letter possessed two kinds of authority in recipients’ minds. First, he was in authority—a boss who could affect recipients’ outcomes within the organization and who, because his letter was personalized to them, would know whether they complied with his request. In addition, he was an authority on the topic, who had displayed his knowledge of the value of the campaign to the bank as well as the inherent worth of the specified charities. When a requester holds that combination of authority traits, we can expect compliance to be notable. Indeed, it’s a combination that explains one of the most astounding patterns of responding in the history of behavioral science.[1]
 Suppose while leafing through your local newspaper, you notice an ad for volunteers to take part in a “study of memory” being done in the psychology department of a nearby university. Suppose further that finding the idea of such an experiment intriguing, you contact the director of the study, Professor Stanley Milgram, and make arrangements to participate in an hour-long session. When you arrive at the laboratory suite, you meet two men. One is the researcher in charge of the experiment, clearly evidenced by the gray lab coat he wears and the clipboard he carries. The other is a volunteer like yourself who seems quite average in all respects.
 After initial greetings and pleasantries are exchanged, the researcher begins to explain the procedures to be followed. He says the experiment is a study of how punishment affects learning and memory. Therefore, one participant will have the task of learning pairs of words in a long list until each pair can be recalled perfectly; this person is to be called the Learner. The other participant’s job will be to test the Learner’s memory and to deliver increasingly strong electric shocks for every mistake; this person will be designated the Teacher.

-----

#### Naturally, you get a bit nervous at this news. Your apprehension increases when, after drawing lots with your partner, you find that you are assigned the Learner role. You hadn’t expected the possibility of pain as part of the study, so you briefly consider leaving. But, no, you think, there’s plenty of time for that if need be, and, besides, how strong a shock could it be?
 After you have had a chance to study the list of word pairs, the researcher straps you into a chair and, with the Teacher looking on, attaches electrodes to your arm. More worried now about the effect of the shock, you inquire into its severity. The researcher’s response is hardly comforting. He says, although the shocks can be extremely painful, they will cause you “no permanent tissue damage.” With that, the researcher and Teacher leave you alone and go to the next room where the Teacher asks you the test questions through an intercom system and delivers electric punishment for every wrong response.
 As the test proceeds, you quickly recognize the pattern the Teacher follows: he asks the question and waits for your answer over the intercom. Whenever you err, he announces the voltage of the shock you are about to receive and pulls a lever to deliver the punishment. The most troubling thing is the shock increases by 15 volts with each error you make.
 The first part of the test progresses smoothly. The shocks are annoying but tolerable. Later on, though, as you make more mistakes and the shock voltages climb, the punishment begins to hurt enough to disrupt your concentration, which leads to more errors and ever more disruptive shocks. At the 75-, 90-, and 105-volt levels, the pain makes you grunt audibly. At 120 volts, you exclaim into the intercom that the shocks are really starting to hurt. You take one more punishment with a groan and decide that you can’t take much more pain. After the Teacher delivers the 150-volt shock, you shout back into the intercom, “That’s all. Get me out of here. Get me out of here, please. Let me out.”

-----

**Figure 5.1: The Milgram study**
The photo shows the Learner (“victim”) being strapped into a chair and fitted with electrodes by the
lab-coated experimenter and the true subject, who would become his Teacher.

_Credit: Stanley Milgram, 1968; distributed by the Pennsylvania State University Media Sales_