9-1-1, what's the state of your emergency? Hey, the tech industry got flipped upside down over the weekend. I was staring at my phone the whole time.

I haven't been so invigorated by any story in like five years. My wife might divorce me because I haven't looked up from my phone. I've just been on Twitter all weekend.

Sam, how are you doing right now with this OpenAI story? It's been awesome. The real winner through all this is Twitter.

Twitter's been great for this, right? Twitter just thrives through all types of controversy. Twitter, aka the Silicon Valley group chat, has been awesome.

Awesome all weekend. It's been awesome. I thought there was a chance that you were just like out duck hunting and I would come on today and you'd be like, what happened?

I'm a Sam Altman fan. I've loved this guy. We've talked about him for years.

I'm a big fan of his. And I love drama. I love gossip.

I read TMZ every day. And so now I've got TMZ on Twitter. It's awesome.

Of course, we're talking about OpenAI and Sam Altman getting fired on. We're recording this Monday. He was fired like Friday, but there's like news happening in real time, like constantly.

Right? Exactly. Like just as of an hour ago, there's news.

So we don't know exactly where this is going to all land. We're going to try to get this out as soon as we can. We had a whole other episode planned today.

We canceled it. We just said, let's do this right now. What's our reaction?

What is our reaction to the OpenAI stuff that's going on? All right, Sam, where do you want to start? I think we should take this character by character, go through all the players that were involved.

And I think we should give them kind of a grade. And they can get it. You know, if they get an A or an A plus, that means they came out a big winner here.

You can get a C. You can get an F. I think we should grade all the players of how this has turned out for them in the, you know, 48 hours so far that this happened.

But do you want to first give a little timeline summary recap? Yeah, so I think you should do it because you've been paying attention to it more closely. But it all started Friday at like, what, three o'clock?

Exactly. Friday afternoon, there's, I get a text message from Ben Levy. He just says, wow, Sam Altman, what the fuck?

Holy shit. What? But he doesn't say the news yet.

The worst. And then he's like, Sam Altman, out. But he like misspells out.

Then he like does the stars not out. Out of what? Where is he out of?

It was unfathomable that Sam Altman would get fired, right? Like in the same way that, you know, I don't expect to wake up and see that Elon Musk has been fired from Tesla. You don't think you don't wake up and think that Sam Altman is going to get fired from OpenAI, which is the hottest private company, probably the most important startup in the world that has gone from zero to 90 billion in valuation in just a couple of years here.

Yeah, it was shocking. It started because OpenAI, I don't even know. Our guy put this in military time.

So what's this? 248. At 248, OpenAI announced a leadership transition.

They said that Sam Altman is departing as CEO because he was not consistently candid in his communications with the board. And their CTO, a lady named Mira, she has become the intermittent CEO. A little over an hour later, Sam Altman said, I loved my time at OpenAI.

It was transformative for me personally. And that he's excited for what's next. Well, let's pause there because the first phase here is wild speculation.

So the speculation is, oh, my God, shock and speculation. So I can't believe this happened. Like an April Fool's joke.

It must have been something bad, dude. You know, he must be, you know, this was a fraud. Did they unleash AGI?

Was there a huge privacy leak that is causing him to have to step down because there's a security issue that he overlooked? There's like this accusation from his sister about sexual assault when they were kids. Is it because of that?

And everybody assumes it's got to be the worst. Until one hour later, or what is it? One hour later?

Yeah, I think a couple hours later, Greg, who was the chairman and was essentially his co-founder of OpenAI, the lead technical guy at the time, or the early days, sends this message to the team. Hi, everyone. Super proud of what we built starting in my apartment eight years ago.

We've been through tough times and great times together, accomplishing so much, doing what should have been impossible. Based on today's news, comma, I quit. Wishing you all the best.

With the I lowercase. The I lowercase. A lowercase I.

And so then, now we enter phase two. Phase two is, wait, Greg's on the board. Wait, Greg is a stand-up guy.

If it was something really bad, Greg would not have just quit with him. This must not be as bad. Is there some kind of power play, jealousy, a coup that's happening here?

Is Sam being wrong? And instantly, I see the court of public opinion shift. And the court of public opinion says, look, if Sam did something really effed up, Greg would not have just followed him out the door and quit.

Unless Greg was in on it. So still a possibility. More likely, it seems like Greg doesn't stand for this reasoning.

So maybe we don't stand for this reasoning. And all of a sudden, you see the Sam army come forward. People who are startups from YC when he was the president of YC saying, look, I don't know what happened here.

But Sam is like, he went to bat for me. So many stories came out that were all the same variety. I don't know if you saw these.

They were all the same variety. It was a startup saying, we had a time when we were screwed. I emailed Sam to be like, hey, here's what's going on, blah, blah, blah.

Sam quickly replied with just something like, hey, make sure you're communicating or just do your best. There's only what you can control. But behind the scenes, he went to war for us.

We found out later that he called all of our investors, threatened to dangle them over the balcony if they screwed us. And he saved our ass and didn't even mention it, that he was doing that. Just in the background, he went through and saved us.

And we found out later that this was true. So I don't know what happened here, but I ride with Sam. Well, an equally big deal is one time I had a customer service question and I DMed him and he replied.

And he solved it for me. Exactly. And a lot of it was he replied fast.

He replied when he didn't have to. He vouched for us when he didn't have to. Man, he did.

By the way, that was out of joke. He did reply to me. Like I had like air.

I couldn't figure something out. I was like, I'm just going to DM Sam. And he replied with like the, he solved my problem.

But yeah, the guy seems like a great guy. And his brother comes out and says to all the people that are gleefully hating today, please know you're betting against the wrong guy. Okay.

Okay. So that kind of foreshadows act two. Act two is the weekend.

So Friday, you get the crazy news dump. Now the weekend, you have news that people start even inside the company start to stand with Sam because they say if there was something bad, tell us what it is. You don't have to say publicly, say it internally.

What does it mean he wasn't candidly consistent or consistently candid with the board? About what? Did he lie?

What did he lie about? How bad was it? You're taking our leader out, our two leaders out now.

And wait, who is the board? Oh, the board is like this combination of people who have no, they didn't build this. They don't even own equity in this, but they're deciding our future because the board is basically one legit technologist.

This guy, Adam D'Angelo, who was the co-founder, CTO of Facebook back in the day. And then he co-founded Quora after that. So you have Adam, legitimate character in Silicon Valley.

And then you have a bunch of other people that nobody's ever heard of. One of them is like that actor's wife. She's like an academic somewhere, never had a job.

Justin Gordon-Levitt. Yeah, exactly. You know, the guy from Inception.

You know, great. The guy from Inception, not Leonardo DiCaprio. That's the first person.

And not even him. He's not the one on the board. And not even him.

Exactly. So you got like, you know, you got her, you got a couple other characters here. But nobody that is, again, no equity, no skin in the game.

And no track record building or operating, you know, complex companies. So that seems a bit weird. They're getting no data.

And rumors come out. Sam's going to have a new company by Monday. Sam and Greg are going to create an OpenAI competitor by Monday.

Which is just like a pretty badass threat to throw down. And so once the team starts to say, they start to tweet out these emoji hearts. Saying, I basically, I stand with Sam.

I don't know all the details. But if you don't come out with any details explaining why you did this, I'm going to probably leave with Sam. And so the board starts scrambling.

And they start trying to renegotiate with Sam to maybe bring him back. And his conditions are like, cool. I'll come back.

You all got to resign and clear my name. You got to bring back Greg. And we're going to put a new board together that's like the board of my choosing.

The board doesn't want to do all that. And so they're kind of stalling. They're going back and forth.

He goes back to the office with a guest pass on his badge. And he says, this is the last time I'll ever enter this office with a guest pass. And then at the last minute, we hear the news come out.

It looks like Sam's coming back. And then Sunday night, it hits. There's a new CEO in town, Emmett Shear.

My former boss, the former CEO of Twitch, is now suddenly the guy for OpenAI. Sam is out. He's in shock.

That was like, you know, what I thought was the end. And before I went to sleep, thinking, okay, we're going to record this pod. I thought that was the end.

Emmett releases an announcement on Twitter saying basically like, hey, I'm here. Here's my 30-day plan. I wake up this morning, and there's more news.

600 of the 700 employees of OpenAI have signed a petition saying, if you don't bring Sam and Greg back and all resign, we're all leaving. 600 of 700. It was actually 500 as of 3 a.m.

And then it got to 650 as of right before recording this. That's basically 100 people woke up and also signed the pledge, including, by the way, the guy who was supposedly behind the entire coup. Ilya, the main technologist, the scientist who was on the board, who was the guy who sent Sam a Google Meet link and was like, hey, can you join this right quick?

And Sam's like, sure. Let me just pop on. Let me just get my microphone.

And he pops on and then gets fired. The whole board is sitting there. And they executed his ass.

Ilya comes out and signs the pledge and says, I'm sorry for what I did. What? And he even tweets out.

He goes, like, I want to get the band back together and make it right. I'm sorry. I regret what I did.

And, you know, we'll try to right the wrong. And then on top of that, before that, that, that they happen, Satya Nadella, the CEO of Microsoft comes out and says, hey, we still support open AI. Sure.

Look forward to meeting the new guy, Emmett, which is just a really funny way of putting it, because apparently they were not consulted and only told one minute before the firing happened that one minute before the press release went out that Sam was fired. So they were blindsided, even though they put they've agreed to fund $10 billion into this company and own 49 percent of it. And then he says, oh, and good news.

Sam and Greg now work for Microsoft. And this is just like the ultimate checkmate move, because, Sam, I don't know if you know this, but Microsoft, not only do they own 49 percent, not only do they provide all of the funding, which open AI requires to to to to. Exist they could pull that at any minute now, because a lot of that funding is in compute credits.

So basically server credits. But not only that, they also have the license to to all the technology. They have the model, the weights, the inference.

They have everything that they need to basically hand Sam and Greg the new the like all of the code and be like, you don't have to start from scratch. Here you go. And so in the end, they got everything.

They got everything they wanted. They got the team, the technology, the money. They got everything.

The most interesting part of all this, though, is the characters, because this is everyone keeps saying this is succession in real life. And it is. It's it's one of the greatest things to happen in Silicon Valley in the last 15 years.

It's a it's a beautiful storyline. We thought Sam Bankman was was a was a gift from the gods in terms of podcasting. This is actually, I think, more interesting.

It's not played out yet. So the story is still going to keep going. But let's talk about the characters.

Let's talk about Sam Altman first. We talked about him. Well, we've talked about him a ton.

But this guy, basically, his background is he's from St. Louis, my hometown. Give a shout out to St.

Louis. Then he moved to Silicon Valley to join Y Combinator at the age of like 19 or 20. He started a company that had like mild success.

I think it raised a fair amount of money and sold for $50 million, of which he walked away with $5 million at the age of like 21. And using that $5 million, he parlayed that into hundreds of millions by investing in things like Airbnb, Dropbox, things like that, because he worked at Y Combinator. Eventually, he becomes president of Y Combinator at the age of 27.

Two quotes from Paul Graham about Sam Altman. And remember, Paul Graham is somebody who invested in Dropbox, invested in Airbnb, invested in, you know, he has seen the founders. He knows everybody in Silicon Valley.

He's met Mark Zuckerberg. He's met all these guys. And so for him to be most impressed by Sam Altman means something.

And he says, Sam Altman has it. You could parachute him into an island full of cannibals. And come back five years later, and he'd be the king.

That's the first one. And then he goes, the second one, he goes, I met Sam Altman many years ago when he was 19 years old. He was a Stanford dropout.

Which, by the way, Harvard or Stanford dropout is the number one resume. That is the number one item. If you go to Harvard or Stanford and you don't dropout, you have intentionally chosen to not have the number one credential you can have, which is Harvard dropout or Stanford dropout.

So he says, within three minutes of meeting him, I remember thinking, ah, so this is what Bill Gates must have been like when he was 19. In three minutes. I don't know what Sam Altman did in three minutes.

But I would love to know. I am fascinated by people who are special. They're kind of the freaks.

I love it in sports, but you can see it. You can see LeBron James at age 17 was like a freak of nature. Yeah.

He had like the equivalent of a 42-inch vert. You know, whatever he did, it was like, yeah, it was like an eighth grader dunking. There's another story that's kind of remarkable.

I thought this kind of tells you about this guy's character. So Sam Altman's gay. He came out when he was like 15 or 16, I think.

You said something about he's from your hometown, St. Louis. There's some story, which is that he came out.

And not only did he just come out as a teenager, which alone takes some bravery. He then like hosted like a pep rally or something like that. He went to John Burroughs.

So in St. Louis, where I'm from, most all high schools are either Catholic or some type of Christian, whatever. And he came out as being gay, but he like went to a, or I think he created like a club, some type of like gay club.

And at a Catholic school, they're like, no, we're not, we're not about this. And so I think he led like a walkout, like a school walkout. That takes a lot of like leadership.

Yeah, he's a very courageous guy. And then, but for like the last 15 years, pre-OpenAI, he was, even though he was president of Y Combinator, he was still a little bit behind the scenes. And even though that he was running this huge incubator and he's a powerful guy, it still felt like, well, why would Paul Graham say this about this kid who still has yet, it still has unfulfilled potential.

A couple of years ago, he starts working on OpenAI. And then all of a sudden we're like, oh, all right. The guy was plotting and it's, it's, he's played the long game.

Now we understand why everyone like looks up to this guy. And OpenAI, OpenAI has basically taken over the tech industry and went from zero to, you know, one of the biggest companies in the world in what, five years or something like that. Yeah, exactly.

So he leaves the most prestigious job in Silicon Valley, which was, you know, president of YC. He's a dean of Harvard, dean of our Harvard. He quits suddenly because the nonprofit research organization he co-founded, you know, he felt like that was the right opportunity.

And he did that. Suddenly it was surprising. I remember at the time I had the thought, I think I've said this before here, which is that I had the thought like if Sam Altman just quit being the president of YC to go join OpenAI, how can I justify coming into work tomorrow?

Like, why would I not also go to OpenAI? Whatever OpenAI is, I knew nothing at the time. But all I knew is if that one of the smartest guys in the world went and did that, maybe I should go do that too.

And honestly, that would have been the greatest career move I ever made if I had done that. Because, you know, OpenAI quickly, you know, changed its structure from nonprofit to becoming, you know, like a capped for-profit thing and became worth, you know, nearly $100 billion in a short period of time, creating ChatGPT, the fastest growing product of all time to get to 100 million users faster than any. And let's go to his two partners, because when he started it, there's a bunch of weird stories that aren't entirely out in the open, but it seems like there was something where Elon Musk funded the business or helped fund the business at first.

He invested $40 million, and he also helped to recruit and convince a few of Sam's co-founders to join. Is that right? That's right.

So basically, when people say, okay, great, Sam's just, you drop him on an island of cannibals, he comes out king. Okay, cool. But what's his skill?

What does he do? And basically, it was like on anything about strategy or ambition. And this is what Paul Graham said.

He said, if there was ever a question on strategy or ambition, I default to what would Sam do? And, you know, Paul Graham was like 20 years older than Sam saying that. So that's kind of impressive.

So what did he do? He basically has a conversation with Elon Musk, and the two of them shared the same belief, which was that artificial intelligence was going to be a big deal, that we would be able to one day realize AGI, which is artificial general intelligence. Think about it as, you know, super intelligence when, you know, AI is generally smarter than humans and kind of everything that we, you know, most of the things that we try to do.

So they both said, that's also kind of scary because we don't know what's going to happen on the other side of AGI. So we should fund research in a nonprofit that will study, you know, fund the research around this so that we can safely create AGI instead of having AGI that kills us all like the movies. So what Sam did was he hosts his dinner in Palo Alto and, you know, he gets Elon Musk there and he gets a few other smart key people.

One of them was this guy, Greg, who was at the time the CTO of Stripe, which was before OpenAI was the most impactful big startup in the world. So he gets a CTO of Stripe. He gets this guy, Ilya, who's like the lead research scientist in AI at Google.

Essentially, he's kind of like one of the founding fathers of AI and deep learning. And so they get a bunch of these people around the table and they basically, Reid Hoffman is there and they basically like, we need to do this. Elon basically agrees to fund $40 million into the nonprofit.

So Elon puts his money where his mouth is. Sam, you know, helps recruit, put the whole deal together, brings the people together. On the way home, Sam's like, hey, Greg, let me give you a ride back to San Francisco.

So they drive back to San Francisco. And what Greg says, what Sam says is the first 30 minutes, it's an hour long drive from Palo Alto to San Francisco. He says the first 30 minutes, Greg just asked me rapid fire, like 150 questions.

Then at the 30 minute point, he goes, okay, I've decided I'm going to do this. I'll quit Stripe and I'll join OpenAI. Whatever this thing is that you're creating, I will join it.

So the next 30 minutes, they started making their plan. Like, okay, what are the first things we need to do? Which tells you something about Greg to do, again, a crazy career move like that to, you know, just have independent mindedness and conviction in something that quickly.

And tells you something about Sam's persuasiveness and ability to like put this thing together. Then what Elon says is that he recruited Ilya out of Google, which was very, very hard to do. And he says it's the reason that him and Larry Page, founder of Google, don't talk anymore.

You know, he used to be friends with Larry. He used to famously, Elon didn't own a house for a period of time and he would just crash at friends' houses. And so he would crash at Larry Page's house all the time.

He says that they got into arguments about AI and that he was really worried about AI and Larry was like tech forward and was like, no, it's going to be amazing. And then he says that, you know, he got pissed when Larry called him a specious, but basically like you are, you're just all about humans. And Elon was like, what the fuck else am I supposed to be about?

Are you not? That scares me even more. I'm going to create open AI now to like defend against Google, which owned DeepMind, the number one player at the time.

And so Elon basically poaches, Elon and Sam poach Ilya out of Google, which took a lot of money and a lot of persuasion, I believe, to get him out. And that he becomes, when he joins open AI, the research community who worships this guy basically followed and they got all the top researchers to join. And that is the founding story of open AI.

That's amazing, right? I mean, I just, this is like drama, movie drama shit of just that, that dinner, that drive home. I mean, this is perfect.

And we're going to have to have Justin Timmerlake stars, one of these guys. And so this brings us to, I think the second character that we should talk about this guy, Greg, who I believe is the unsung hero in this whole thing. Because Sam Altman is kind of like the hero.

He's the hero, right? He's the CEO. He gets backstabbed.

He gets wronged. He's the martyr. He had to suffer.

People come out and they're all supporting Sam and sharing. Like, it's like a funeral for Sam on Twitter the other day. He's like, oh, I remember that once Sam responded to my customer service request.

Like, oh, I was on a bike once. And Sam, you know, he moved over in the lane so I could go by, right? Like, everybody was just sharing their favorite Sam memory.

And then nobody was really talking about Greg. Now, Greg, in my opinion, shifted this whole fucking thing. Because at first, it was like, damn, I don't know what Sam did.

Must have been horrible, blah, blah, blah. As soon as Greg came out and was like, yo, on this, I quit. And they're like, Greg's the number two.

He's on the board. He was the chairman of the board, I think. They're like, if Greg doesn't think this was right, I don't think it's right.

And so Greg single-handedly, like, shifted the perception and the narrative around this whole thing. And the board didn't counteract that. And so I think Greg was the real hero of this.

And then what I did was there's some amazing blog posts that anybody who's a real nerd about this stuff, if you just really love kind of like the lore, the canon of Silicon Valley, you got to go read this. Greg has blog posts up on his blog about the early days of open AI. And I think he blogged the early days of open AI last week.

No, this is eight years ago. This thing started a long time ago. And he talks about, like, they didn't have an office.

He's like, all right, just come to my apartment. And he's like, here's the four of us in our apartment. He's like, I didn't know anything about machine learning.

So I did two things. Number one, I asked Ilya, what is the number one textbook about machine learning? I bought it and I studied it religiously.

He's like, I read everything there was to know about deep learning and machine learning. He goes, and this is the former CTO of Stripe. He's not like a non-technical dude.

He's known as like this incredible, one of these 10X or 100X engineers. And he says, I didn't know anything about deep learning. So I just dedicated myself to go read, you know, page one, chapter one of the book.

And I'm going to take notes and I'm going to ask a ton of questions. He goes, two, while these guys were setting up their research stuff, I did everything else. He's like, oh, your back looks a little uncomfortable.

You need a pillow? Oh, you guys thirsty? I'll go get smoothies.

And he's doing literally all the like intern grunt work those first few months to get them set up. He's like, and it basically was alternating between research would do something. Then research would get blocked.

And I would say, oh, what's blocking you? And they're like, oh, it's taking forever to run this training center. I have to like organize this data.

And then Greg would stay up all night and basically like do the engineering. Because people don't realize engineering and coding is very different than AI research. And so he would do the coding that would make the researchers go faster.

He built basically all of the infrastructure so that researchers could do great work. And even with GPT, like there was a story like, you know, they ran the model and the output was kind of like, ah, like it was so-so. And then Greg like locked himself in a room for two weeks and he came out and suddenly GPT worked.

And people were like, what the hell just happened? And he's like, yo, I blacked out and I did that. And so he has these great blog posts and photos of those early days that I thought was kind of amazing.

So Greg was born in 89, which puts him around 34 years old now. He joined Stripe in 2010, became CTO in 2013. So he was CTO of Stripe when he was about 24, 25 years old.

And then he left Stripe to co-found OpenAI. So he was only 26, 27 when he started working on OpenAI. It's pretty amazing.

These guys are freaks. Unreal. It's wild.

It's unreal. And by the way, what did you give? You forgot to give a grade.

So Sam Altman, he's going to win no matter what in all of this. So I think he was going to get like, let's say a B plus, right? He was going to get a B plus.

Why? Because you got fired. You got backstabbed by your own people.

Not great. Not a great thing to happen. Two, they haven't said what you did, but you did something, right?

They weren't just going to fire you for nothing. So like you did something. We don't know what it is.

Unknown. Okay. I can't give you an A for that.

It looked like he was going to get the job back, which would have been great. But then he didn't. So it didn't happen in the end.

So even though you got some support from your team didn't happen until the Microsoft thing happened, which was literally like, imagine playing a game of chess. And you're like, oh, I think I got this guy. You know, I have a five piece to three advantage here.

His queen is out. And then you look up from the board and he's holding, you know, a Glock to your head. And that's what happened to Ilya here.

Basically, it's like he's now he's at Microsoft. They have the license to all of the technology. They have all the training data in the world because guess what?

90% of computers are PCs that run Microsoft, that run, you know, Windows. He has all the funding in the world. He got paid.

I'm sure there's, you know, like Satya had to bring Sam and Greg in before the stock market opened on Monday just to kind of like not have this be an issue for Microsoft. That they got screwed here. They put a bunch of money into a lame duck.

And so he got everything. He got the tech. 600 of 700 people are saying they're going to follow him there.

So he got the team. He got the money. He got the funding.

And he got it all in 48 hours. And they were basically like, yeah, they're going to lead a new subsidiary of Microsoft that's going to do research on AI. It's like, oh, you mean OpenAI Part 2?

So now he has to walk away with an A+, right? Like, you can't knock that. And he's got the good guy label unless they come out with some new information that shows that he did something effed up.

Which something has to come out. There's only three options, in my opinion, of how the story for Sam ends. Option A is it's an unforgivable sin.

I think that that is not likely. But it is possible that what he did is just, well, you're done. Option B is he goes back to OpenAI, becomes CEO.

I think that was more likely than not going to happen. I think. But option C is he stays at Microsoft.

And I think in a decade or five years, he becomes the CEO of Microsoft. Which is now worth $5 trillion or something at that point. Yeah.

It's $2.7 trillion today. Yeah. So he's going to turn out okay.

So now this other guy, Ilya, he looks like a schmuck here. So he's a loser here. He looks like.

Ilya gets an F. He gets an F. There's a little bit of likability with him where it's like, oh, you're just a brilliant scientist, artist, turn.

Who was, who was, you were, you were manipulated in here because you're just a scientist and you don't understand human interaction. So if he plays. So we should explain one thing, which is what are the possibilities of what Sam did that might put Sam in the wrong or Ilya in the right?

So there is what you're calling the unforgivable sin, which I would say, by the way, not a great track record of anything being unforgivable. Let's say the really bad personal stuff could be the could be one reason why, in which case I would say that's a completely fair reason to remove him. If they did an investigation, found out that that was true, that they're in the right for removing him.

That's defensible, but they just haven't said anything. Reason number two is safety concern. So Ilya is famously like the reason he's doing this is literally he's worried about AGI.

He doesn't want the world to end. And what initially people thought was Sam says all the right things about safety, but also Sam is like, you know, capitalist. He's a entrepreneur.

He's he's a he's a hard charging guy and he's running forward here. And maybe they're saying slow down. He's saying, no, we don't need to slow down.

And they're saying, Sam, this is too risky. And he's saying, no, no, no, this is not risky. We got to move forward.

That's what it looked like. The situation was. And it was made crazier by the fact that I don't know if you saw this.

He did an interview the day before. And he said something like this. He said.

I've been lucky to be in the room four times now. The last one was just a couple of weeks ago where I saw something that pushed the veil of ignorance forward and the frontier of technology to us. And I pushed the veil of ignorance away and the frontier of technology to us.

So basically he's saying like there's been like three or four mind blowing moments, you know, about AI. I've been lucky enough to be in the room. The last one happened a couple of weeks ago.

Wait till you see this. It's going to stun people. And so some people are like, yo, did they like create the monster super intelligent?

Like, did they create AGI? You know, has AGI been achieved internally? And he like randomly posted on Reddit not long ago.

AGI has been achieved internally as like a joke, I guess. So some people said maybe they've stumbled into something and this guy's going too fast. And it's, you know, like the scientists, you know, around the nuclear bomb saying, no, no, no.

We got to like destroy this thing or we got to like slow down. This is getting too crazy. That would have been the other reason, which would have been, again, defensible, especially given that OpenAI's charter is specifically says we're not about increasing shareholder value.

We are about, you know, safely building AGI to benefit all of humanity. So that is their charter. And if they thought this guy's moving too fast, putting that at risk, I would say they are completely in the right to do so if they believe that to be true.

The bad part is, again, they've come out with no evidence that that that is the case. They haven't explained themselves. So nobody believes them.

But that's true. The third reason. So, you know, you have the really bad thing.

You have the safety argument. And the third thing is essentially it's just a power play. They're annoyed by him.

They don't feel like he listens. They feel like he's getting all the credit or he wants fame and fortune and power play. Let's get this guy out of here.

And we will we get to run and own this thing. And that's like a jealousy driven thing. And I don't know which of those is the most true.

I don't know what you think. But, you know, it seems like. You know, none of those are perfect explanations.

I think I'll say what I think maybe later. But it's number three, I think. I think it's number three.

Let's talk about let's let's come back to the board. But let's talk about Emmett Shear. Because you are one of the handful of people or, you know, however many people who have had a relationship with him and understand.

And so last night at 1 a.m., Emmett basically said, I've been the guy that's been picked. He put out this really good tweet where he explained what he was doing. The funniest part, I thought, was he's had the job now for 12 minutes.

And he did a wonderful job of saying the word are. He goes, our products are going to be this. Our team is going to do this.

We are going. And it reminded me of that meme where there's a guy who he goes, hey, I made this. And he hands it to a stick figure.

And the stick figure goes, you made this? And then the first guy leaves. And the stick figure looks at the thing and he goes, I made this.

And it's the whole point about on the Internet where people steal stuff. I actually think Emmett's a great guy. So I'm just messing around.

But I thought it was amazing how he's like, 12 minutes later, our company is going to do this. What do you think about Emmett in this role? He's been getting a lot of criticism because he previously shared online that he's like, I actually think we need to slow things down.

And a bunch of people are like, this is ridiculous. Don't slow down. Whatever.

But he seems like a really thoughtful, great CEO. Am I wrong? So Emmett, you're right.

I worked with Emmett for about two years. Got to sit with him in hundreds of meetings and see how he thinks and hang out with him, have beers, and just kind of talk to him. He came on the podcast.

I talked to him for an hour there about AI stuff. You always said he was really thoughtful. He's extremely intelligent in a broad way.

So most people are not that intelligent that you meet. You meet some people that are like, oh, they're above average. Then you meet some people, as you say, the oven burns hotter.

And it's just very clear he's just got more horsepower in his head than most people. I think that's great. I think, you know, as much as we like to say that, like, hard work is what matters, like, yeah, you know what also matters?

Like, intelligence is also a really strong attribute. It's like, you know, like, yeah, you know, Steph Curry's got great skills, but like LeBron is 6'8", 250, right? Like, you know, size and speed matter.

I hate when people downplay intelligence. And I'm like, guys, let's just admit some people are born smarter just like some people are seven feet tall. There's a reason why 20% of Americans who are seven feet tall and below the age of 30 are in the NBA.

You just, you're better. You're better at that particular thing. Same with intelligence.

And in the same way that height helps you with basketball, intelligence helps you with running companies, right? Like, that's a thing. So, Ebbett is extremely intelligent.

He is amongst the most intelligent people I've ever met. So that's the first thing. Second thing is he's got depth and breadth.

So a lot of people are really, really intelligent in one specific domain. It seems like this guy, Ilya, might be one of those where he's just extremely, extremely technically intelligent. But it seems like in the game of, you know, soft power and politics and, you know, people and all that, he, you know, had a pretty boneheaded way of doing this that didn't work out.

To his own tweet, I deeply regret what I did. It was handled very poorly. So, you know, I think, you know, some people can really, really smart in one technical domain, but they're not, don't have a breadth of intelligence.

I would say that Ebbett is wide and deep. So he's technically very strong. He was a great engineer.

They built Twitch, one of the, you know, the best live streaming products. And it was him and this guy, Kyle. Kyle went on to build self-driving cars.

And Ebbett ran Twitch for like, whatever, 18 years or some shit like that. So, you know, between Justin TV and Twitch. And so he's very good technically, which is important because it's a deeply technical product.

He, you know, he said to me, the other thing, one thing when I was talking about AI, he's like, he's like, yeah, like once you understand how transformers work. And I was like, well, let's stop there because I have no idea how transformers work. So like the rest of your sentence, because he said it like, yeah, it's easy.

I mean, just once you get out transformers work, it's like, you know, blah, blah, blah, blah. Just anybody could go watch a video. We've had a couple smart people in this pod.

And they've tried to use analogies because I'd be like, I don't understand what you're saying. And they're using analogy. And I'm like, can you please use an analogy for your analogy?

Like, I think we had a biology on here. And he was like referring to the Battle of the River of Thames in World War II in order to like describe crypto. And I'm like, guy, I don't know what the Battle of Thames was.

Like, this doesn't make sense to me. Right, right. Exactly.

You know, I'm asking for a lunch bowl over here and you're making gourmet. Yeah. Let's do this right.

What's his soft skills like? Well, his soft skills, I would say when I experienced him, which was like, you know, whatever, he's been, he'd been running the company for over a decade as CEO. I thought he was good, not great.

So for example, I think he always knew what to do. Like if you caught him when he was calm, he would give great advice on the people side of how to handle something. However, in the heat of the moment, he was prone to falling into like debates about semantics, about words, about data that would make people feel like shit.

And he would like win the battle and lose the war type of thing with people. And so I don't think he was great with that. But I also think Twitch was like a bunch of very like kind of, it was a community product with a bunch of very like sort of woke people in the company that were like very touchy feel about stuff.

You know, I think open AI is going to be his type of people, you know, like Emmett was better in meetings where all the people were engineers and product people. He was worse the more that the people were, you know, we got legal PR, cobs, you know, marketing, you know, those meetings went worse for him, I thought. And so I think he'll have less of that here.

But he also is like, apology, like he'll reference the Battle of the Bulge, like he'll reference, you know, well, the judicial system in Ireland back in the 1500s, what they did was really interesting. It's like, dude, why do you know this? He's like, well, I've read about all the judicial systems.

I was very interested in how governing has changed over time. It's like, that's your casual reading. He's like, yeah, like, I don't know.

Is that weird? And it's like, you know, somebody is really good when they don't even realize it's weird when the thing they do is like really fucking weird. And so he has a very, very wide set of knowledge.

Now, he's getting kind of labeled as a decel. I don't know if you've seen this, like a decelerationist, meaning like somebody wants to slow things down. Because as soon as he's got names, basically a suit.

Yeah, kind of like a suit or like a doomer, you know, like, oh, this is this guy's anti-technology, which is pretty silly. And it's like, you know, if he could be technology, he would, you know, like he's a technologist through and through. They're calling the guy who invented Twitch a boomer, basically.

Yeah, it's stupid. And so, you know, a friend who, a mutual friend described it well. Because people dug up all his old tweets.

And he said, if opening eyes at a 10 right now in terms of speed, you know, it should probably be at like a one or two. Because, you know, you just don't want this cat to get out of the bag. And so I want to read you what he, I have the transcript of what he said on our podcast, which when he came on about AI.

So I asked him very simply. I said, is AI going to kill us all? And he goes, maybe.

I go, it's interesting you say maybe it's going to kill us all. Because, like, you're pretty, like, pro technology and everything. You're an optimist.

And he goes, well, it's because I'm an optimist that I'm scared. If I was a pessimist, if I was like, oh, this AI thing's overhyped. This technology is not that impressive.

It's just a nice little magic trick. It's nothing real underneath it. If I was pessimistic, I would be less worried.

I'm optimistic. I am extremely impressed with how these work. And I see a pathway where this is going to get better very fast.

And at some point, it's going to be able to self-improve. That's very scary because we don't know what happens on the other side of that. He's like, it's because I'm optimistic.

And the second thing he said was, he goes, here's the analogy. You know, in biology, there's, like, there's now, like, ways that you can synthetically do things. We know we can edit genes, for example.

And we can, like, add an extra leg to a sheep. Or we can, like, modify a virus. This was, like, you know, COVID, right?

Like, you can modify a virus and make it more spreadable. And we all saw with COVID how dangerous that capability is. That, like, this thing, you know, if this leaked from a lab, that's really, really bad.

Like, you know, that was a big mistake that technology made that, like, you know, fucked up the world for a few years. And so he's like, you know, we have regulation. And I think everybody kind of agrees.

We should maybe not go super fast and make it easy for somebody to, like, print smallpox in their home. Right? Like, we should maybe not give that capability to everybody.

And maybe we should, like, slow down to make sure there's some oversight so that we don't do something really bad that, like, creates a super virus. He's like, people get that when it comes to biology. They don't really get that when it comes to AI.

He's like, with AI, here's the thing. AI is really good at, like, the one thing you need in order to be really good at AI, at developing AI. He's like, AI can code.

It can write code. It can read everything there is to know about a subject in an afternoon, become absolute world expert at it, and then it can translate that into action. It can translate to writing code.

It can also design chips. Yeah, it doesn't do either of those two things perfectly right now. It's not amazing at writing code, and it's not amazing at designing chips, but it can do them.

It's within the zone of things that AI can be good at, the type of things that AI can be good at, which means that over time, it's going to be able to write code that designs AI. Okay, and design chips that make AI better. And once that thing can improve itself, it's going to get fast.

It's going to get really amazing, really fast, faster than anyone can expect. And maybe that's a good thing. Maybe it all works out, but also maybe it doesn't.

And that's like, he's like, even if I think the probability of a really bad thing happening is low, it's the consequences are so bad. We're not just talking about a virus that screws up your computer or even a pandemic that gets people sick. We're talking about this could destroy, he says, it could destroy all of the value of the light cone, which I don't even know what the light cone is, but I don't want that.

So he's describing even if it's low probability, we should just be really, really careful about that and make sure we don't screw the whole thing up. And a friend reached out to one thing. They go, they go, every saying like Emmett's going to want to like slow this down and stop it.

He's like, no, no, Emmett's smart. Emmett knows the game theory of this, the prisoner's dilemma. If you go too slow, somebody else will create AGI before you because you slow down to zero.

So somebody else will get there before you who may not share your moral beliefs around safety. So you can't go too slow where other people get there first. You don't share your safety views, but you can't go so fast that you don't actually build it safely.

There's a middle ground to seek. And so I think that's the best description of this, where people are trying to label him as one thing and knowing what I know about him. That's just not true.

Well, let's go like through rapid fire of like some other story points. And we'll make that quick. And then also we've been there of what we think is going to happen.

One quick story point for you. If you like drama. We got to do final grades before we do stories.

Final grades. So the board, what do you grade in the board? Oh, they're fucking losers.

They're the worst. They look horrible. They're going to get.

You got an F. If it stands for fucking loser. Yeah.

Yeah. Is there an F. They're the worst.

I mean, it doesn't matter what the truth is. It's all about perception. And they look like the worst, including Adam D'Angelo, the founder of Quora.

Right now, he looks horrible. So F. They get an F.

Do you agree? Yeah. Agreed.

What do you give Emmett? He's 12 minutes onto the job here. TBD.

C. He's actually actually it's actually like a D or a C at the moment. He's getting dragged, I think, which isn't fair.

But no, he looks like he's a loser here because of perception. Right. I mean, he's taking the hero's job.

Like it's hard to look good regardless of how amazing he is. Right. Right.

And what about Satya, Microsoft? He gets a B. He looks pretty good.

I mean, he's the man. I mean, he's kind of made a resurgence for Satya or for Microsoft. I think that I think there's a real world where Bing actually catches up to Google in terms of search.

And Microsoft is going to become just an even bigger company than they already are. So, yeah. I mean, he's a man.

He's a him and Sam are the masterminds. I got to give him a plus. The dude, you know, mobilized over the weekend.

And before the markets opened and could hit Microsoft stock, he had basically acquired OpenAI for negative $100 billion. He acquired OpenAI, which is incredible. And so now he got OpenAI out of the nonprofit capped profit structure.

It's just super for profit inside Microsoft. He got the key talent, you know, Sam, Greg, all of the key people, 600 of the key people. And now they just own the whole thing instead of 49%.

That's an A+. He crushed it on this one. He's the man.

So let's do the storylines. Yeah. Here's one quick storyline.

Have you heard of Fairchild Conductors? Do you know what that is? I've heard of it, but I'm not a history guy.

So what's the story? Isn't there something like the traitorous eight or something? What is that?

Yeah. So basically, there was a big company called, I think it was called Shockley Conductors. And they made conductors, computer chips in the 60s in Silicon Valley.

People were pissed off at the guy who owned it, William Shockley, I think his name is. He was brilliant, but just a pain in the ass. And so these eight guys said, hey, you got to bail or we're bailing.

And the CEO goes, see ya. And so these eight people went and started Fairchild, which was basically the equivalent is like NVIDIA. But back then in 1960.

And it basically birthed Silicon Valley, right? That was like the, that was the seed round of Silicon Valley. Yeah.

And they were famous. Their culture was famous because they were casual. So it was like where nerds could come and be casual and where like the best actually, best ideas actually won.

And that was where the whole like culture of Silicon Valley arguably started there. And then the offshoot of Fairchild Conductors was basically IBM. So IBM was founded by one of the founders of Fairchild.

Andy Grove, the guy, the famous manager of, I think he was the CEO of IBM. He came from there. The founders of Sequoia Capital, Kleiner and Perkins, I think might have spun out.

I mean, like basically it was, there's just all these people, but the story of the treacherous eight is what they're called is very similar to this story. And so if you're interested in this type of like stuff and you, and you could actually go and read that book and you could see a lot of similarities between what is going on now. So this is like our version of that.

And so it's going to end well, I think for Greg and Sam, because I, it ended really nicely for the treacherous eight. Right. So that's an interesting thing to look into.

By the way, my prediction is that they, they unwind this whole thing and they revert back to open AI, by the way. That's my, like, it hasn't happened yet, but I think the final step now, now that Ilya signed the pledge being like, I quit and I'm also going to go work there. It's like, what is the point of even having the open AI entity?

If 600 of the people, including all of the leaders are gone, I don't think they want to be inside Microsoft necessarily. So I think what's no, no, no, no, I think this was the final straw. And by the end, I bet by the end of the day today, uh, they get a whoopsie daisy undo on the whole thing.

And, uh, Sam is back as CEO of open AI and, uh, they just, the board quits and they get a new board. That's my, my prediction, by the way. And I think I believe, I believe that that prediction I think is the same.

I think there's long tail predictions here, which is new startups aren't going to want to have board of directors. Um, I actually think that's the wrong takeaway. Brian Halligan from HubSpot, he wrote, he's like, no, the takeaway shouldn't be to not have a board.

The takeaway should be have a good board. Um, and I think so, but I think that potentially like the governance structure of companies might actually change significantly because people are going to be like, uh, they're going to, they're going to have PTSD from just hearing this story. And that actually is going to have downstream effects that are quite large and in a weird way could even impact like the venture capital industry.

I think that is, um, a real possibility. I totally agree. And I think it's so stupid.

So right now there's so many startups that are reading their, their governing documents about the board and thinking through, do I need to change my board? Here's my public service announcement. Don't worry, bro.

You're not open AI. You're not Sam Altman. And, uh, your board is also not these schmucks either.

And nobody cares. And like, you know, the, for a startup, like, don't worry about your governance structure right now. Like you should be doing the standard vanilla things, uh, you know, put competent people there and then don't worry about it too much.

Like you need product market fit. You don't have this problem in the same way that like, when you hear what's going on with like Uber or Facebook, it's like, you're not Uber and Facebook. You don't have the same problems that they have.

Don't suddenly start spending your energy over there and take your eye off the actual main problem that you need product market fit. You need growth. I think the takeaway here is open AI's board was stupid.

I say that was actually a strategic mistake. It seems like on Sam Altman's part. Also, I think the whole nonprofit shtick that was stupid too.

Um, TBD, if I'm going to be right on that, but as of now, it's like, it would have been a lot simpler. Or maybe if this is just a board or this is just a normal board where they have equity in the company. They started with a good board.

They started with Elon Musk and Reed Hoffman and all these like legit players on their board. And then one by one, they all quit. So basically like Elon quit cause things weren't like, they weren't listening to him and he took his ball and tried to run home.

Uh, Reed Hoffman quit cause he started a competitor. Another guy quit cause he wants to run for president. Another person quit.

Yeah. It's like basically five of the original board members quit for different reasons, either starting competitors or conflict of interest or, uh, running for president or whatever. And, um, this is what they got left with.

Yeah. So hopefully that gets changed. Um, what are any other takeaways?

I think, um, what were you saying about this was the best and the worst of us? Yeah, that was kind of my big picture takeaway. Like, I feel like this was the best of Silicon Valley and the worst of Silicon Valley all in the same weekend.

Um, you know, the best I thought was things like, you know, what Greg did when he was like, yo, I'm out too. I quit even though they tried to, they, they wanted to retain him. They weren't firing him.

It's like, yeah, that's a real co-founder, right? That's, that's a, that's a ride or die sort of ducks fly together moment. And I thought that was, uh, that was bad-ass.

I thought that was the best of us. And then I thought the worst of us was like this, like stupid board that has no skin in the game that doesn't know how to communicate that didn't like handle this well, just fumbling and bubbling and removing a founder from there, removing basically the greatest founder alive, you know, outside of Elon Musk from their company that they created for what seems like no reason. And if there is a reason you got to like say it.

And even if you say it in a way that wasn't like, doesn't get you sued, like, you know, maybe that's why they're not saying anything, but you have to at least tell your team, you have to give more than what they did. Uh, they handle it better than what they did. Um, and if it was so bad, then don't negotiate with him to come back.

Right. Like if it was that bad that he shouldn't have 24 hours later, been in discussions to come back. Um, you know, so the board I thought was, you know, it was the worst of us.

I thought, you know, Twitter was alive and popping and it really did feel like it was the Silicon Valley group chat. That was kind of the best of us. And the worst, worst of it was like, you know, it felt like gossip girls all weekend.

And, um, that's kind of lame. And it was a bunch of, you know, like speculation, wasted energy. And, you know, like I saw these Twitter spaces going on for hours and hours of people just like discussing, like, you know, it was a real housewives episode and they can't believe that Jenna said that.

Right. Like it just seemed like, you know, it wasn't, it seemed like gossip. And I thought that was a waste of time.

You know, I thought there was a whole bunch of things that were kind of like the best and the worst showed themselves in the same weekend. You know, maybe, um, you know, it could be that there actually is a legitimate, you know, crazy safety concern. And like this guy was going too fast.

And, you know, this Ilya guy was maybe the hero and was pumping the brakes, even though it screwed up his own economics. If he really was standing for something that he believed in, right? Like it could be that it was that, or it could be that it was a jealousy power play and take him out.

Right. We don't know, but I just thought there was a whole bunch of best and worst. Another one was like just this instant labeling, like these like tribes.

Like, I don't know if you've seen this, like E slash ACC thing. Is that the E cell D cell? Yeah.

But basically there's, there's a whole bunch of people in the Twitter bio that hit E slash ACC. And I've been seeing this for months. I have no way to, I didn't even know what the hell this was, but it's except you're, you're an effective accelerationist.

Right. So it was basically like kind of a play on the effective altruist or whatever altruism that Sam Bankman-Fried was doing. That's pretty stupid.

I think. One is basically like pedal to the metal, you know, tech forward, progress forward, technology optimist. Uh, and it's like, that's the cool club to be in.

And then anybody who's like saying, Hey, slow down. You're a D cell, which is like, you know, um, it's the D word. Basically it's a, it's a slur.

It's an insult. And to me, this was, again, it's the worst of us. It's the, it's like people in Silicon Valley make fun of politics.

It's like, Oh, I'm not left or right. It's not that simple. It's not Republican Democrat.

I'm not, I don't fall into these stupid party, you know, tribes that are just blindly, you know, following the herd. And it's like, we're doing the same thing. Uh, this E cell D cell shit is the same thing as Democrat, Republican, red, blue, left, right.

Um, it's an oversimplification of, um, a massive oversimplification of what's going on. And so I thought that was kind of the worst of us too. Final prediction.

My prediction is in the next 24 hours, all of this is going to be undone and things will be back to normal. That's my prediction. Is that yours too?

I, maybe we'll give it 48 hours, but I think at this rate, 24 hours. When I was in second grade, my class had a field trip and, um, they said, they told the parents, I said, Hey, you need 20 bucks to come to this field trip. So my mom gives me $20 in the morning and I go and I'm excited about the field trip.

I don't think I'd ever been on a field trip. This is my first. And, uh, they're like, Hey, okay, put your thing over here.

Sign your, give me your assigned waiver and put your 20 bucks. And I'm like looking around. I'm like, where did my 20 bucks go?

I was right. This is my desk. It's not here.

I'm looking under the table on the desk. I check my backpack. I'm like, what the hell?

Somebody took my 20 bucks. I can't go on the field trip now. And so I go to the teacher and I'm like, miss, like, um, somebody stole my $20.

And she's like, Oh my God. It's like stealing. Like this is stealing money from a kid.

Like that's not okay. And she's like, are you sure? I'm like, yeah, it was right there.

And so, uh, she turns the world upside down. She starts, she's like, Hey, blows the whistle. She's like, everybody sit down.

Who has the money? And it's just silence. Nobody raises their hand.

And she's like, okay, we'll try this a different way. I'm going to put a jar outside and we're going to walk out one by one. And I want the $20 to be in the jar by the time this is done.

No harm, no foul. Everybody walks out. Everybody walks in.

She comes back. Jars empty. And she's pissed now.

She's like, okay, I gave you a chance to do this clean. I gave you a chance to do this publicly. Now we're not going on the field trip, guys.

Guess what? And, uh, and I'm like, Oh my God, this is like getting the field trip canceled. This is crazy.

Not just for our class. She tells the teacher next door. She's like, we don't earn, we didn't earn this because there's been, you know, one of our core values has been betrayed here.

And where was the $20? And then I'm like, I gotta go to the bathroom. And I get, I get up and I'm like, miss, can I go to the bathroom?

She's like, yeah, sure. I get up and I feel this like scratchy feeling in my sock. And I'm like, I reached down and I'm like, I put the 20 bucks in my sock this morning.

Like, that's right. I just remember. But here I am.

You're like a drug dealer, dude. What do you do? Here I am.

And now I'm like, what do I do? I'm like, the class is going to be so mad at me if they realize this is in my sock the whole time. The teacher is going to be so mad at me if she realizes that I accidentally did this.

I didn't mean for all this to happen. And so I went to the restroom. I took the 20 bucks, put it in the toilet, and I flushed the toilet.

I went back to my seat. Did you really? Did you really do that?

Is that really how that ended? No, that made for a better story. But I did hand it to her.

And then we went on the field trip. But I thought it'd be a better story. But that thing did happen with the sock and it wasted half of the field trip day.

And that's how I feel Ilya feels right now where he's like, I did not mean for all this to happen. Like, this got way bigger than I thought this was going to get. And whoops, can I just like give you this 20 bucks and we pretend this never happened?

And that's what he's trying to do right now. And more power to him. I've been there.

I feel you. All right. Well, we're going to see what happens.

That's the pod.