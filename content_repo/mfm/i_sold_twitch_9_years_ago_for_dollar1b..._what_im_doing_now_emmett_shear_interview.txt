Is AI going to kill us all? Uh, maybe. Emmett Shear is the CEO of Twitch.

It was acquired by Amazon in 2014 and joins us now. I started Twitch to help people watch other people play video games on the internet. The creator and co-founder of Twitch.

Watch other people play video games. Who knew? Emmett knew.

I guess that's the answer. What types of ideas are you noticing or standing out to you that are interesting? For the first time in maybe five or seven years, it feels like credibly trying to start a consumer internet company, like the ones that like I was so excited to start in 2007, is like potentially a good idea.

And that's because of AI. You mentioned AI might become so intelligent, it kills us all. This podcast is really growing.

I don't want the world to end. I think it's going to be okay. But it's such, the downside is so bad.

It's like it's really, probably worse than nuclear war. That's a really bad downside. But I think of it as a range of uncertainty.

And I would say that the true probability, I believe, is somewhere between... All right. What you're about to hear is a conversation I had with Emmett Shear.

Emmett was the creator and co-founder of Twitch. If you don't know about Twitch, I don't know, you're living under a rock. It's like one of the most, I don't know, five most popular websites in the States right now.

It is a place where you can go to watch other people play video games, of all things. Watch other people play video games. Who knew?

Emmett knew. I guess that's the answer. So he was the creator, co-founder of that and built it up.

It's a multi-billion dollar company. They sold to Amazon many years ago, seven years ago or eight years ago for about a billion dollars and has grown many times since then. He finally retired after 17 years of the journey.

I got to know Emmett because he bought my previous company. So we got acquired by Twitch. Emmett was like my, you know, quote unquote boss for my time when I was at Twitch.

So I got to see this guy firsthand. He's the real deal. And I've been wanting to get him on the podcast since those early days when I first met him.

I was like, this guy is great. We talked about a bunch of things. So we talked about some ideas of like how he would use AI if he was going to create another company.

Like I think he's good. He's retired now from that game of operating a company. But if he was going to do it, this is what he would do.

So we talked about AI ideas. We talked about why he thinks AI might kill us all, might, you know, be the big doom scenario, which is interesting because he's not just a guy who's going to go cry wolf. He's not a pessimist.

He's not just a journalist who hates tech. This is a techno optimist. This is a guy who believes in tech, is a very, very intelligent guy.

And he sees, you know, a probability. He gave us a percentage of probability. He thinks that could be sort of the doomsday scenario and why he thinks that that could be the case and what we should do about it.

So we talked about AI. We talked about some of the frameworks that he has for building companies. We didn't talk too much about like the origin of Twitch.

I feel like he's done that a bunch of times. So we kind of stayed away from that. But it was a wide ranging conversation.

And for those who are watching this on YouTube, I apologize. The studio that we booked in San Francisco, they screwed up the video. So we don't have video for YouTube.

We just have the audio only version. So you'll see our profile pictures. My bad.

Sorry about that. You know, got to pick a better place. Got to pick a better studio, I guess.

But anyways, enjoy this episode with Emmett Shear. Somebody said, creativity is not like a faucet. You can't just turn it on.

I think actually if you've polled like 100 people, most people are like, yeah, of course. Creativity is a sacred, special thing that only happens if you've meditated in the morning. The room is perfectly right.

And you've had your L-theanine in your coffee or whatever. And you were like, no, for me, it's very, it is like a faucet watch. And you're like, I could just write and just keep generating more ideas.

Yeah. I love that for two reasons. One, I love that you'll just be like, no, actually this, that's like a consistent thing I've seen you do.

And the second is, I think that's very true about you. And I wonder, is that practiced or is that innate? Like if I, if there was a researcher studying you when you were like 10 years old, do you think they would have been like, oh, this person's different in these ways?

What would have seemed different or special about you at the time? Um, I, the, if there was a nurture nature break on this, it happened very early because by the time I was 10, you would definitely notice the same thing. I'm not really that different.

I would be much less effective, but like as a 10 year old, I already had that same experience. But you were different than other 10 year olds. Yeah.

Other 10 year olds. Well, I would actually say I was less different than, I think most people, actually most children have this experience already. I think most 10 year olds and definitely most five year olds are capable of generating ideas for what to do about something or to like play pretend almost indefinitely.

They don't run out of ideas. It's as you get older, somehow you, what you learn to do is you learn to stomp down the ideas that are like bad, um, and to not say dumb things. But the more pressure you put on yourself not to say dumb things, the more your, uh, inner idea generator, it like gets disrupted.

And I say, I say a lot of dumb things. Like when I'm generating ideas, I may not put weight down on them, but most of the ideas will be bad. They'll have something obviously wrong with them.

And they give you this advice. And when you, if you go to like someone who teaches you to brainstorm, like no bad ideas here, that's obviously not true. There's lots of bad ideas.

Most of your ideas are bad. Yeah. The actual advice is like, don't stop at the bad ideas.

Yeah. What you're, what you're trying to do is you're trying to disable that sensor that most people have installed that like is like, no bad, no bad, no bad. Don't, don't be stupid.

Don't be stupid. And I think I was like mal-socialized. I, it never occurred to me to, to have that.

Like I, I didn't, I never got the sensor installed and why that is the case. I'm not sure. But I actually, I think I'm the one who is unchanged in some sense.

I'm a little more childlike in that way. And everyone else is the weird one who like, why, how did you wind up like damaged by your life that you're, your inner wellspring of creativity has been crushed. And I think that process is actually very simple.

You, this process goes up with all kinds of things in people's minds. You start from some capability, something you can do some behavior. And if when you do that behavior or you try that thing, you receive negative feedback, which can be external, or you actually think even more often internal.

You're like, oh, I screwed up. Oh, it's bad. Oh, I don't disappointment.

You learn not to do that thing pretty rapidly. And so that leads you to doing it less, which means you're less skillful at it, which tends to lead you to doing it less, which is that that cycle ends in you being very bad at something like I'm bad at math. No, you're not.

Everyone can be like the kind of math you're talking about. Everyone can be the kind of math. And people say I'm bad at math.

They don't mean I'm bad at like abstract algebra proofs. They mean I can't do arithmetic or algebra, basic algebra. And that's just imaginary.

Like everyone can do that. It's easy. They got stuck in one of these like spirals and now it's getting out of one can be very hard.

And I guess I think that's what happens to people's creativity. I don't know. I didn't go through the process myself.

And so I got, so now as I'm saying this out loud, actually, when I, the idea that I have good comes up for me is like, oh, well, maybe what it is, is that I had better ideas. That's like, that's the other. I got in the reward.

I got the reward loop or, or I had an environment that was unusually positive and positively reinforcing for me having ideas. And so I would have ideas and it would go well. That would lead me to having more ideas, which, and more practice at having ideas, which would go well.

And then you wind up just never breaking that loop. I have a trainer who comes over to my house and he always says this thing to me because like my kids will come down during the session. And I'm always like, oh, sorry.

Like obviously annoying. My two year old is here almost getting hurt in all the weights. And that's probably like not what you want in your session.

Someone was like, oh, sorry, sorry, sorry. And he's just like, dude, no. And he's like, kids and dogs.

I go, what? He goes, I love to be around kids and dogs. They got it right.

They know life. He's like a dog is like unconditional love, happy, playful, you know, super loyal. He's like, what's not to learn from a dog?

I want to learn everything I can from a dog or kids. He's like, look at what she's doing. She just made up a game on this thing.

Like we're here trying to do a serious workout. She made this her play place. She can't wait to come down here.

He's like, I wish all my clients wanted, couldn't wait to come down to the gym. And I was like, damn, this guy's right. And one of the things I like is figuring out people's isms, their philosophies.

And you're like, oh, I thought of one on the way here. Explain what it was. It was, have you tried just solving the problem?

What does that mean? So there's a, there's a meme on the internet. I think it started with weird son Twitter, which is like, have you tried solving the problem by, and then an infinite list of possible.

And there's just the tweet is always, have you tried solving the problem by like ignoring the problem? Have you tried solving the problem by spending more money on it? Have you tried solving?

And one of my favorite ones of those that has become almost like a life motto is like, have you tried solving the problem by solving the problem? And that sounds dumb, right? Like that sounds, it's one of those like Zen cone pieces of advice that when you first hear it is like, are you, are you serious?

Like that's the advice is solve the problem by solving the problem. But what you notice when you try to help people with problems a lot is oftentimes people will have a problem. It'll be really obvious what the problem is.

And they'll come to you for advice for like, well, how can I deal with the consequences of this problem? Or how can I avoid needing to solve this problem? Or how can I get someone else to solve this problem?

Or have other people solved the problem in the past, which are closer to the right answer or what can be the right answer. And the point of the saying is to remind you that sometimes the way to solve the problem is just like, just to actually try solving the problem. Like don't deal with the symptoms.

Don't accept the symptoms. Don't, don't find a hack around it. Like the problem is the website is not fast enough.

And instead of like trying to figure out how we can make a loading spinner that distracts people from that fact. What if we just made it so fast that you don't need a loading spinner? It's interesting because that's a good, that's a very good advice when the problem actually is solvable.

I mean, your people are flinching away from it because something about it is aversive, even though the problem isn't really unsolvable. Like if they worked on it for six months, it would go away and it's worth solving. Whereas there are these problems where like you're trying to make a perpetual motion machine.

You're trying to do something that is actually too hard and solving the problem by solving the problem. You should actually stop trying to solve the problem. That's a huge mistake.

And you should be looking for a hack around needing to solve the problem. You should be looking to live with it more effectively. But I find actually on the balance, at least with most people I, I talk to, I help most people I know, I think it's maybe it's people in tech, like love that love the hack.

They're always looking for the easy, fast solution that cuts around you to solve the problem. And it's very helpful. It's the most often helpful form of that advice.

In my opinion, it's like bringing people back to just solving the problem. I find that the advice I like the most or the sayings that resonate with me the most are the ones it's like you spot it, you got it. It's like if it's the one I, it's the advice I needed.

That's why it resonates with me. That's why I like giving it out because like I personally experienced it. Have you personally experienced that?

Or what's an example where you remember trying to do everything but solve the problem? And then you finally realize, shit, I should have just. Solved the problem.

It's an interesting question. What is it? You spot it, you got it.

It's like noticing is half the battle. Basically. It's sort of the smart person version of whoever smelt the dealt it.

Yeah, yeah, yeah. It's like a hundred percent. If you, you only notice this in other people because you've seen it in yourself too.

Yeah, yeah. Otherwise you wouldn't be as observant of it. My version of this is we give the advice we need to hear.

Yes. Yeah, exactly. Which is same basic idea.

It's actually not always true. Like that's one of those really good heuristics where like, sure, half the time when you give advice, it won't actually be for you. But half the time it is.

And noticing it is so powerful that like you should just check every piece of advice you give for like, wait a second. Is this advice I need to hear right now? When it comes to the like, have you tried actually solving the problem?

I think I'm pretty good at that in general. I think that I often give it to myself in a more meta sense. Like it's advice I often need in a more meta sense of like when I'm confronted with like a thing that needs to be programmed, I will often go just program the thing.

But I have a tendency to like look for ways that I can solve the problem and not that the problem can be solved. And for me that this almost always like what if I wouldn't ask somebody else for help? And I just like it doesn't even occur to me to go to go do that.

I'm just I'll just I'll just indefinitely dig try to go solve the problem myself. I'm not really trying to solve the problem. I'm trying to solve the problem while avoiding having to ask anyone else for help, which is like not I'm not really trying to solve the problem.

But actually, no, weirdly, I think this is one of those things where it's almost like the creativity thing. It was a shock for me to realize other people don't do that. Your self-actualize on that one.

Yeah, what's a piece of good advice that you're bad at taking? Oh, that's a that's a an excellent one. I think the big one there is like, you know, listen more like I give this advice so much of YC and it's 100% something that I need to get better at, which is like you go into the user interview and you have all these ideas and thoughts and you need to not be surfacing those.

You need to actually be focused on move your attention to them and really be interested and care about what they have to say and your opinions. And what's what you think is true is irrelevant. And I am I'm much better at that than I used to be.

And I I also it's one of those things like being reminded, like, let's just chill out for a second and listen is almost always good advice for me. And something that I and as much as I give fairly often. But like, it's hard for me to to take on.

One of the things I really liked that you showed me once I remember asking you when we were at Twitch, I think we were working on a problem that was like reminiscent of early days Twitch with like the mobile mobile stuff in different countries where it's like, oh, we're not the leader or we need to like create from scratch, which wasn't a muscle that a lot of people there were flexing at the time. And I was like, hey, do you have any stuff from the early days of Twitch? And you sent me a thing which was like, here's all the user interviews.

Like, here's my doc from all the user interviews it which was basically from what I understand. There was like a small universe of people that were already doing video game streaming. And you were like, cool.

Let me call all of them. And let me ask them like three questions. And if I could just get these answers, these three questions that should give me a little bit of a roadmap of blueprint of understanding what do I need to do in order to like win in this market?

Yeah. Can you take me back to that? Because I like that for two reasons.

It was a simple and b seemed like a focused intensity that you found a point of leverage and you pushed. Yeah. I think two things happened to lead to that.

The first was like the realization, obviously, we wanted to win in gaming. The streamers mattered. And at JustinTV, we'd always been like streamers and viewers are equally important.

And I finally made a decision. I was like, no, no, no. This product ultimately is about streamers.

And if this doesn't work for the streamers, it doesn't work for anybody. And then I had the realization. This is one of those epiphany moments where I truly saw.

I have no idea why anyone would stream video games. Like I don't really want to do it. And I have all these.

I could. I saw myself building products for these people for the past four years of JustinTV and not really having any idea why they did the thing they did at all. And I sort of I saw like, oh, I'm just making this up.

I have no idea. I said, I don't know the answer. I could know the answer.

Like there is a there is an answer out there. These a bunch of people know it, but I don't. And that triggered me to be like, I need to know.

I need to understand like these this these 200 people. I need to understand their mind. And I did about 40 interviews probably.

And I didn't want to know like what they thought we should build because if they knew what we should build, they would have my job. And I've talked to enough of them before to know that they had no good product ideas. I I wanted to know, like, why are you streaming?

You what have you tried to use for streaming? Like, what did you like about that? Like, what did how did you get started in the first place?

What's your biggest dream for sharing? What do you wish, you know, someone would build for you? And I didn't ask them, what do I wish someone would build for you?

Because I thought they would have a good idea. I asked them because the follow up question was really the killer one, right? They they would say, I wish you'd build me this big red button.

I'm like, great. I built you the big red button. Like, what what does it do for you?

Like, why is your life better after I built that? And then they would tell me the real thing, which is like, oh, I would make I'd make a bunch I'd make money that month or I'd get a bunch of new fans who like loved me or my fans who already loved me on YouTube would be able to watch me live. More of them would.

And I was like, oh, that's the real answer. Like, why? You don't you don't want the button.

You want the fans or the money or the I call it love the like the the sense of reassurance and and positive feedback that your creative content was wanted. But you're a smart guy. Those love and money and fans.

I'm sure you would have guessed what are the streamers want? False. What did you think?

It was a revelation that people would want money because I was like, you're streaming like, you know, whatever, 12 hours a week. If we let you monetize the rates we can monetize today, you'd make like three dollars a month. That would like that didn't occur to me that would be a positive thing.

Like, yes. Oh, my God, that would be amazing. And I was like, wait, wait, you're serious.

You would like three dollars. I'm like, I don't know. Overpromise like I'll build you the monetization, actually.

But like you would really be excited if it only produced like a tiny amount of money. And they're like, absolutely. I've just the idea that I can make money doing this would be so exciting.

That had not occurred to me because it always is easy for me to make. I was a programmer. I had summer jobs interning for Microsoft.

If you're a programmer, you can get a summer job interning for Microsoft. That's like pays many, many years of that level of streaming in three months. Like, why would I?

It didn't even wasn't in my worldview that that would be so important to them. And of course, I knew they wanted a bigger audience, but the degree to which they valued even one more viewer and the degree to which they didn't care about anything else, like they they wanted people to watch them. They wanted to make money.

And I'd ask about other things like, do you want the video production? You know, like improve the video production of cooler video production? And they'd be like, yeah.

I'd be like, OK, but like what? What's good about that? Like, what do you like about that?

Like, well, I'll get more. I'll get a bigger audience. And it was really the realizing realization that like it was just those three things basically explained 98 percent of their motivation.

And we could even get didn't move on that could be ignored. So a good example, that's like polls. Everyone would ask for polls.

Seems like a cool feature. Live polls, of course. Are you going to have a bigger audience with the live polls?

Not particularly. Are you going to make more money? No.

Is it does you really do you really feel more loved if you're running a live poll than if you're just like asking chat and having people post it in the chat and say it? No, it's the same. You got the feedback.

It's cool. So this product is actually cool to see the chat blow up. It's cool to see the chat blow up.

So you're saying that this feature is worthless. Yes. In fact, potentially negative, in fact.

And so it would always be on the list of like things that would sound like they might be cool. And we just would never build it entirely correctly because it wasn't going to move the needle. And the thing that's really hard to teach there that I've got.

I've been a YC visiting partner for this batch. I've been trying to convey to people. It's very hard to get them to do it is like you have to care fanatically about these people, these people as people and these people as as in the role they're doing as these people as streamers.

And what they believe about their reality is you to accept as base reality. That is how they see the world. And that is what's going on.

But like you need to like literally have no regard for their ideas for how to solve the problem. And it's a little paternalistic in a way, but it's it's more of like just respecting that they are experts in this thing. And you need to understand them in that thing.

And that what people are looking for when they are looking for the product idea from the person is like they don't want to do the work. They don't want to take responsibility for it's my job. I have to solve the problem and no one's going to tell me what the answer is.

There's no teacher. There's no customer. It's up to me to come up with the truth and and then defend it when other people are like, no, that's wrong.

I have to be able to say, no, no, no, let me explain this. Let me explain why this is actually a good idea. And that's scary.

You're responsible. I think actually it's a probably why the just solve the problem advice is bouncing around my head, because a bunch of the fear of founders have about addressing these things, I think, comes down to a willingness to take responsibility for solving. Other people's this other person's problem, like they're going to come and dump a bunch of problems on you and it's your job to solve it for them within the constraints available.

And there's no if you come up with the wrong idea, it's on you and you can't you can't trust anyone else to do it for you. What are you seeing in this YC batch? So your visiting partner, exciting time with AI, probably like, you know, half or more of the batches doing something with with AI.

Yeah. What's exciting? What are you seeing?

Where do you see the puck going? Ah, so it's interesting. I would actually say that at least in this batch, I think this might have been different the previous batch.

But by this batch, use of AI is no longer interesting. It is out. No, no, no.

AI is so in it's like it's like being an AWS startup or like being a mobile startup. Like, what do you mean you're a mobile startup? Like, are you are you building a social media network?

Like, what's the of course you have a mobile app? And now it's like, of course, you're using LLMs to solve problems. That's just like if you weren't doing that, I would think you were a dummy.

Like, I don't understand. Like, that's not a you wouldn't even bring it up. It's not even an interesting topic of conversation.

The question is, like, what what are you doing? No, that's not entirely true. There's about some percentage of the batch.

I don't know. It's between 10 and 20 percent, I'd say, that's legitimately building like AI infrastructure because there's a need to build a bunch of infrastructure there. Those are actually those are AI companies.

But like when people hear AI company, I don't think they they think back end infrastructural support for AI. They think of using AI to like do things. And I actually couldn't tell you what percentage of the batch is AI from that point of view.

All of them, maybe. I don't know. Like, why wouldn't you use it?

Even if it's only for a minor thing, there's always something you can use it for. It's a very useful technology. What types of ideas are you noticing or standing out to you that are that are interesting?

Is there like, you know, for example, I remember when I first moved to Silicon Valley, suddenly the kind of like bits companies started doing really well. It was like, oh, Uber and Airbnb and my online offline. Yeah, it was like, oh, wait, this this used to be like a taboo.

Like it was like, no, it's supposed to be a software company like you have to ship T-shirts. What are you doing? I would say, like, stay away from trends.

The offline offline companies that started the trend did very well. Uber is a great company. Airbnb is a great company.

But they were off. DoorDash is a great company. But at the time that was they they were doing something that was not allowed.

They were they were they'd found an opportunity that had been ignored. Almost all the online offline companies that get started after Uber, DoorDash, Airbnb are big. Being like, we're going to be the Uber and DoorDash and Airbnb of X.

Most of those companies did not do very well. Is online offline bad? No, it's generated a bunch of incredible companies.

Jumping on the trend was probably bad for you. And so whatever I tell you is like the trend I see. I don't mean trend.

I guess what I mean is I think you're a person that is really good at looking at a situation like looking at a box of stuff. And identifying correctly what's really interesting in this. Yeah.

Yeah. Interesting to you. Yeah.

No, I understand. I think I understand what you're asking. So like what I think is changing in the world right now, having observed this, is that consumer is back.

For the first time in a long time, many, and by a long time, it's like internet standards, like five years or something. But like for the first time in maybe five or seven years, it feels like credibly trying to start a consumer internet company. Like the ones that like I was so excited to start in 2007 is like potentially a good idea.

And that's because of AI. AI means there's a whole opportunity to sort of reimagine how consumer experiences can work ground up. And what's cool about consumer is for B2B SaaS, the experience isn't the product.

And so reimagining the experience does not reopen a necessary. It can, but it usually does not reopen a segment. In consumer reimagining an experience, 100% reopens the segment because the thing you're selling is the experience.

The thing, the reason people use your product is it's a different experience. And in B2B SaaS, it's not the experience. It's the what?

Yeah. People actually care what it does. And like the, the, the pricing model and the, and like the adoption, it's very practical and you can make people jump through hoops.

If it does a thing, because there's a lot of money for the corporation and money and labor and people are paid to use your product and it's a whole different thing. And so AI adds new capabilities, new capabilities enable new segments of B2B SaaS to be created that will generate some amount of growth. In consumer, it does a really cool thing.

It's like mobile. It reopens every segment as like, oh, now that you assume mobile exists, now that you assume AI exists, what could you build now? And that's very exciting.

I don't have answers for that anywhere because like, you know, we'll see, like that's a whole thing. We did other thing in consumer. It's a bunch of lottery tickets.

Like nobody knows. It's like singular genius that works out. Right.

Like you could see like, okay, mobile comes photo sharing became like open again. Right. The window has opened.

The windows are open for photo sharing. Turns out it's Instagram and it's Snapchat, which is going to use photos as text messages. Like who could have seen that?

Photos have a few different use cases and Instagram and Snapchat took two of the best ones. The, the fact that photo sharing is one of the most important segments and that, you know, sort of posting them and messaging with them are the two important, most important things to do with them and that's what it's like, am I going to use? Because this is something like, the value of this platform seems blinding obvious in retrospect.

And if you'd had to predict that in 2007 or 2008, like good luck. Yeah. Like nobody, nobody, nobody correctly predicted that stuff before it happened.

I mean, not nobody. If you did correctly predict that you made a lot of money and congratulations, you're really good at consumer slash you got lucky. We will find out when you try to do it again.

I think that in AI, actually, I have a theory for like the, what one of the ways this will disrupt a bunch of businesses in AI, especially in consumer, a huge number of businesses can be conceived of as effectively being a database with a system of record that has like a bunch of canonical truths about the universe and each of them is a row it's like yelp is like a big database that has a bunch of rows and the rows are like restaurants and local businesses and they have a bunch of facts about them like they're where are they located what are their hours they all in that database row and it's all text and it's all there's a bunch of messy stuff out in the world and it's been digested into something that is searchable and comprehensible and usable in an app for you to use and most of the work of turning the messy real world into the canonical row is done is done at right time by the users so that's how ugc apps work in general a bunch of your users go out into the messy world and they turn it into a row in a database and if they include a photo or a video as part of that it's like attached to the row as a fact about the restaurant here's a restaurant here's a hundred these 150 photos are facts about its menu but they're attached facts they're not the basis and where i think ai has opened up the possibility for is a huge inversion there what if the thing you did you gave us was just a video of your meal and fo or you know photos of you know but ideally just like a video of your of the meal of you talking about the meal of whether we had a good time or not you and your friend shooting the about what did you do like that one no i like this one like and what if we just saved that video raw and then an ai watched it and extracted a cached version of that of the the metadata but truly like if we decide something else is important like we we we didn't get noise levels we're like noise levels would be a good thing to get instead of like recollecting data from everyone they have to start a whole data collection for us to get that we just go back re tell the ai oh yeah also grab noise collection levels from all of these videos in fact maybe we don't even as a product have to go do that maybe as a customer i can literally just be like what's the noise level at this restaurant and the in real time the ai can go re-watch the video and tell me or the you know i ran a search and there's these 15 restaurants and i'm like oh actually sort by noise level we don't have noise level pre-recorded but it's it's in all the videos the ai can very quickly watch all the videos in parallel and sensor by noise level for me but it wasn't even in the database to start with right and i think that inversion i'm using yelp as the example because it's i think a very familiar thing for most people of like review it's pretty easy to imagine a bunch of video reviews of everything and that being the system of record instead but you can describe some phenomenal number of consumer apps as being that in him you type anything to a text box you're you're participating one of these system of record things what if it's at the video what if you just what if you assume video is deeply indexable and understandable by computers what should the experience look like and i think it looks a lot more like snapchat or tick tock like experience but but then different because you need map it's not exactly like anything it's a new kind of thing but it's it starts probably with the camera open which is weird right like a yelp that starts with the camera open that's a that's not yelp today and it's it's it's disruptive because it's yelp's whole value prop is we have all this great highly meticulously groomed data and if this is true then that becomes entirely worthless we throw that all away and we just want to watch a video in fact it's worse than the videos and so suddenly the playing field is leveled between the startup and yelp and that's a that's a huge opportunity for disruption and so i think that you can take that you can reapply it to any product where you fill out forms and that's like a general purpose consumer thing you can now do kind of like build it for mobile was and i think in some cases it will be very powerful and like that will be the new winner i think in some cases the incumbent can kind of add videos or like it's not really better and like the incumbent will just win like it won't disrupt everything but if you pick the right thing not only will it disrupt the incumbent the new thing may be dramatically better for some things like i actually think actually yelp in some ways is a bad example i think the data yelp has with the photos and the reviews is like 90 as good as a video system of record probably but you could imagine something with a video system of record where it's not so obvious what to even put in the highly processed version of the data in the text version of the data and the video version is a lot better and then i think not only can you disrupt the incumbent you can 10x the size of the segment like you this becomes a good segment now where it wasn't particularly before so like chat gpt is a great example of this in action that everybody kind of has now played with which is you take google which is like oh we have our value is this entire sort of rank of web pages based off of terms and we have we understand basically what should show up in this in this hierarchy and it was really good for finding stuff and chat gpt was like cool you could ask a question to try to find a link to an answer or we could just give you an answer or even better forget questions and answers like what if you just give me a command and i could just make something instead of finding things i could create things for you right and all of a sudden it was like well how did they do that it's like well they just basically slurped up the internet and then you know trained the ai to do it they overfit a statistical prediction algorithm on every domain of human knowledge like this is my theory i'm pretty sure it's true but like statistical prediction algorithms in general work very well we found the innovation is on a prediction algorithm that works better than normal but the way it works better than normal is really interesting it's not actually particularly out that it outperforms traditional algorithms for prediction on normal amounts of data it's that it keeps working as you just dump more and more data into it and more and more processing on that data into it like most machine learning algorithms you kind of you overfit very fast and more processing more explain it if you imagine like you've got a bunch of data cloud of data points and they're kind of vaguely in a line underfit is like you like just draw something just like across random as a random line that doesn't look like anything like the shape of the dots a well fit curve is like you draw a line through the dots and there's kind of noise of like things that are random above and below but it's like if you look at it's like yeah that actually does fit the data like the the underlying predictive facts about the data well while ignoring the noise and then if you overfit it like you get this like really wiggly curve that touches every single dot exactly but like when you get a new thing it like will miss that because it over predicts it predicts too much of the thing and so when you get new data it actually doesn't predict that very well okay and so normally what happens is you try to like dump more data and more a compute into a normal machine learning algorithm you get diminishing returns very quickly we're like it just doesn't perform that much better with twice as much data and twice as much compute the clever the cool thing about the transformer based attention all you need architecture is that it it continues to benefit from more compute and more data in a way that other ones didn't and so what that likes you do is run it on a much bigger domain than normal run it on everything don't just don't just run it on normally as you added more as you add more area it like degrades the quality elsewhere no it just do everything and just put a ton of compute in and now you get something that predicts pretty well against everything which is to say it like it seems to be kind of intelligent the evidence seems to suggest to me that it's said it's overfit when you ask it to predict something that is either in the in the set of things it was trained on or a linear interpolation between two things it was trained on it's quite good at giving you the thing you asked or but linear interpolation between five things but if the things you're asking are all in there and it just has to find the way to blend them together it's good at that when you ask it to actually think through a new problem for the first time like what's an example there are seven gears on a wall each alternating there's a flag attached to the seventh gear on the right side of the gear where it's pointed up right now if i turn the first gear to the right what happens to the flag like that's a anyone who's like this is a breakfast question for you this is what you pondering in the mornings if you have pen and paper and time you can work this out no problem right you just just draw the gears when you turn the first gear to the right it turns the left ones the ones that the other ones are left and then next to the right and there's a general principle there that like the gears alternate which is if you ask chat gpt it knows that general principle but it won't but like but then you say it doesn't it hasn't no one asked dumb gears on wall flag questions like this is not a a thing that has been is in its training set and you have to kind of logic your way through it and like figure out okay we should like i'll do turn left turn right turn left turn right turn left turn right uh oh the flag is on the right it's pointing up so when the last gear which is the same as the first gear turning right the last year it's odd number so it's turning right also the flag will rotate down to the right clockwise cool like i can work that out it's not actually that complicated and i bet that question will be answerable that's a pretty easy question and if chip gpt for i tested with three three point five if four doesn't answer it five will but like the fact that it struggles at all with that while being so brilliant at combining other stuff really shows that it's it's overfit right it it knows how to answer problems that it has seen before but when you give it a truly novel kind of like combination of problem it struggles a lot because it's it's i would say um you know if you give it a sort of the formal psychiatric psychometrics approach it has a very high crystallized intelligence but a pretty low fluid intelligence right now now that could change but like today that's the state of affairs and do you bring this up in order to say what you say okay i think it's overfit and it's strong in this area and weak in this area what's the so what of that for you is it that are you trying to say that's a little bit overhyped or are you trying to say dude just wait till it can do both are you trying to say definitely problems are doable now definitely just wait till you do both because that's a that's a whole different thing that's scary uh but the current thing that is mostly crystallized intelligence is really good at a very if this is why it's a class i was saying it's a clever trick right it's really good at a big set of tasks which happens to be the set of tasks that like anyone has ever written stuff down about explicitly like all explicit human knowledge that's like a very big domain there's a lot of things that can be solved where there's an explicit examples of people solving that problem or a linear interpolation of those problems in the domain of all human knowledge the fact that it doesn't generalize is irrelevant it's immensely powerful with you don't need fluid intelligence i guess is that is the point for it to be very useful but it doesn't let you do everything people that you hit these boundaries these weird boundaries where just like like wait a second you can't do that like no it's it's i can't do that at all um novel problem solving it's just terrible at so what about let's walk through two examples i want to hear your take on this so you gave the yelp example another thing that's kind of like rose in a database is something like spotify where it's like oh i want to go listen to a song here's genre artist song length uh you know some algorithmic popularity similarity to other songs in some way and but spotify's value if spotify's value is in the playlists i would agree with the analogy to spotify because playlists are an example of this kind of like databasey human data entry thing spotify's value is mostly in the set of all of the music itself the licenses and all the music itself and so i don't think spotify is a great example because the human data entry parts of the database if that all just got deleted tomorrow it would like not hurt spotify that bad well the thing i'm thinking about is what if the licenses don't matter so what happens if generative music is just awesome to listen to in a hyper yeah personal way oh and it likes yeah these are the types of songs that emmet likes that's a different that's a different insight that i think is also possible which is like it's not about being able to analyze and extract from media it's about being able to create media because the video system of record is enabled by the ability to understand and read video and comprehend it generative is is the opposite it's like you we can oh we can make all the stuff music in particular is sticky against that people don't want new music they want old music they want the music they love already the music they grew up with and that is the that cycle is what causes record labels and just to stay in charge whether you still listen to the rolling stones right like the other thing i would say about that one is like the music's not that good yet like maybe someday but like it's really it's really not that good yet well i'm going to caveat this if it gets if the general intelligence level goes up a lot all bets are off it'll make some really great music for us before it maybe takes over the world and kills everyone but let's assume that doesn't happen soon i think it's going to take longer than people think we go out to make great music though no but if we do go out we're gonna go out with some great music and amazing it's gonna be a great two or three years before we all like we all go but until that point uh making really good like new great music is hard actually and i think that rick rubin's great success demonstrates why artists will still be important the ai can generate lots and lots of music but it's not going to have the the fine judgment of distinction of the ability to say like this song not that song and actually what it will do is it will de-skill the music making process on one vector the ability to like literally create the sounds and it will greatly upskill the music making process another vector the ability to to cure that is curate to give explicit exact feedback like rick rubin does ai is going to turn us all into rick rubins for for generative ai like that that skill set of the ability to have a musician come to you and help them produce their best music that's the thing you need to do because it's easy to generate a thousand cuts but there's infinite cuts you could generate so how do you direct the the the how do you shape that in the right direction and and mine and discover i think it's kind of cool it'd be interesting you'll get a different set of people who will be optimal with that right this data is wrong every freaking time have you heard of hubspot hubspot is a crm platform where everything is fully integrated whoa i can see the client's whole history calls support tickets emails and here's a task from three days ago i totally missed hubspot grow better you mentioned ai might become so intelligent it kills us all this podcast is really growing i don't i don't want the world to end and life is good life is good here well i'll ask the question clean for the for the intro dramatic hook is ai going to kill us all maybe like walk you know how you walk through how you a smart person who's an optimist about technology but a realist about real uh what is the way that you think about this or how would you explain this to you know a loved one you care about who's not as deep into technology how would you explain to this you're their trusted source on technology what do you say to them so it it is because i am so optimistic about technology that i am afraid if i was a little bit less optimistic and i was like this ai stuff's overhyped yeah yeah yeah look at this nice parlor tricks but like we're nowhere near building something that's actually intelligent like and like the engine all these engineers who are working on who think they're on something they're full of it's going to take us thousands of years we're not that good at this stuff technology's not going that fast i'd be like this is fine it's great actually it's good news it's a new trick we learned excellent it's because i am so optimistic that i think that there's a chance it will continue to improve very very rapidly and if it does that that's it's that optimism is what makes me worried it's sort of the analogy i like to give on that front is like a syn biosynthetic biology i'm quite optimistic about synthetic biology that i have several friends who've worked against in bio companies uh it shows a lot of promise for fixing a lot of really important health problems and it's quite dangerous because it will let us genetically engineer more dangerous diseases that could be very harmful to people and that has that's a wade pro and con it's like nuclear power makes nuclear weapons and nuclear power they're both real the christian nuclear weapons is dangerous you doesn't think you don't have to be a techno non-optimist to like think that that's there's a problem there i think it was good that we didn't go have every country on earth go build nuclear weapons probably and likewise in syn bio i would say that it would be we actually we already have these regulations in place we should probably over time we'll need to strengthen them and improve the and audit the oversight and build better organizations to monitor and regulate them but like we regulate whether people can have the kinds of devices that would let them like print smallpox and we regulate whether you can just buy precursor things you need to go print stuff and we keep track of who's buying it and why and like that is wise i'm glad that we do that i don't like calling for a halt syn bio but like if we weren't willing to regulate it i would call for a halt it is vastly too dangerous to do to learn how to genetically engineer plagues and then not to have regulation around people's ability to get the access to the tools to engineer plagues that's just suicidally dumb and i just because i am pro technology i believe that we should absolutely develop the technology and that we should regulate it that seems just straightforward and obviously true to me i think it's easier for people to understand that in the syn bio one because the concept of like engineering a plague seems like obviously a thing you could do and very obviously very dangerous and obviously enabled by technology the ai thing is more abstract because the threat it poses us is not posed by a particular thing the ai will do the way the plague will happen analogy i like to use is sort of like you know i can tell you with confidence that gary casperov is going to kick your ass at chess right now and you ask me well how is he going to checkmate me which piece is going to use i'm like oh i don't know and you're like you can't even tell me what piece he's going to use and you're saying he's going to checkmate me you're just a pessimist i'm like no no you don't understand he's better at chess than you the what means he's gonna checkmate you and i don't i don't know quite know what happens or people deny that like i think what the big thing is they don't really imagine the ai being smarter than them they imagine the ai being like like data in star trek like kind of dumber than the humans about a lot of stuff but like really fast at math like that's not what smarter means like imagine the most savvy like most smartest person you can think of and then make them think faster and also make them even better at it and not smart in just one way like smart at everything like a great writer just insight after insight and like can pick up syn bio in an afternoon because they're just so smart that's smartest person you know and then they should keep pushing that and like that's all that person is obviously dangerous if they're if they that person isn't a good person they're obviously dangerous like imagine this really really capable person then imagine them wanting to go kill a bunch of people or something it would be bad now the thing about ai that then kicks it over the edge is that that person can't self-improve easily you meet this person who's like super strong super like talented great with people great great intellectual mind they can't turn around and like edit their own genome edit their own upbringing and make v2 of themselves with all the skills that maximally smart person can come up with that like is even smarter than them but that's like expli we're explicitly the ai is good at programming and like chip design and like it can explicitly turn back on itself and rev another rev of that and the new one will be better at it than the first one was and there is no obvious end point to that process like there probably is at some level a physics-based endpoint to that where like you can't actually just keep getting smarter forever there's some but we don't really we don't understand the principles of intelligence at all like with most things we understood how to make electricity far before we understood what electricity really was like with it's generally how we that's how scientific progress works we usually understand we gain the ability to create a manipulative phenomenon well before we deeply understand how it works we didn't really understand what fire was for quite a while you could use fire really well the same thing is going to happen here we're using the ai but we don't understand its limits at all we understand the the theoretical limits of how far we'll get and if moore's law is any indication we can keep getting at the very least it can keep getting faster indefinitely whether or not it can get smarter or not even human love just human level intelligence if you capped it at human level intelligence which there's zero reason to think it will stop at human like it will almost certainly blow past us but like even if you cap it at human intelligence imagine a hundred thousand of the smartest person you know all running at a hundred x real-time speed and able to communicate with each other instantaneously like telepathy those hundred thousand people could credibly take over the world like they don't have to be smarter than a human for that for that that army of von neumann's right like so so the argument to me goes in several steps it's like can you build a certain level of intelligence and then it's like okay let's i think i actually think a lot of people do believe that like computers are smart google is smart calculators are smarter than us at math i think it's not hard for them to believe that the ai is going to be far smarter than human beings where i think a lot of people then don't make that last leap is sort of like but then it'll have an agenda or a motive or any yeah for anything to happen so how do you address that last point of like what is the what are the scenarios you worry about when it comes to like now the direction of that intelligence so you build this thing and it's really good at solving what is intelligence fundamentally but the ability to solve a problem right so it's really good at solving problems and it's going to solve the problem by solving the problem it can just go right through the problem and solve it because it's really good at solving problems but we've just defined it as like that's that that's the kind of thing it is super good at solving problems and so you tell it somebody builds an ai and in all earnestness tells it they're smart they don't even tell it go do a thing although they absolutely will by the way they will just tell it to go do a thing but let's say we try to be careful and we ask it give me a plan to stop the war in the democratic republic of congo right now right which would be a good thing for the world i think we should that war is is going to hurt a lot of people give me a plan for that and i try to i caveat it that that does this that does that that does this you know that here's what i mean by a good plan this is one of these like evil genie bargaining things right like it'll give you a plan and it's make giving you a plan that will cause you to solve the problem but like its definition of solve the problem is there's no war in the drc well one would there be no war in the drc is like all the humans in the drc are in stasis fields that means they don't die and it's all you know and oh we added a caveat that the gdp has to go up too so that so it also the plan results in you know corporations in that in that area all trading with lots of money with each other so the gdp is very high and and when i say this it sounds like a science fiction thing and the problem is it's casparovic chess i don't know if i could do it i would be the super intelligent ai that could take over the world i can't give you the the exact plan because that that's yeah but i think that makes sense which is that a human with a human with motivation can get the ai to work for it and the dangerous i think that the main thing is that the human doesn't need a bad motivation i think people imagine well humans have had powerful tools for a long time bad people with powerful tools have done bad things for a long time the solution is good people with powerful tools countering them the problem is even if you're a good person with a powerful tool good things to ask for reasonable things good people would ask for you know like let's uh maximize the all-in free cash flow of this corporation over the uh lifetime of the business and extend the lifetime as long as feasibly possible ends in like the world destroyed being destroyed and the core of the earth being turned into you know being turned into cars for the company to sell and the i think the best analogy that that works for some people here is like when we create the ai we are creating a new species it's a new species that is smarter than us and even if you try to constrain it to being an oracle and just answering questions not taking action to be a good oracle one must come up with plans then and then a good oracle can manipulate the people around and will manipulate the people around it no matter what like the whole point of like the greek myth is like when they tell you when they tell you the prophecy when you trust them a trustworthy oracle tells you a prophecy the prophecy often becomes self-fulfilling it's very easy for that to happen that's not an unusual thing and i think even more to the point actually i'm going to start this over at some level more to the point we won't just make oracles we are already building agents we will build the predictive ai and we will put it in a loop that causes it to optimize towards goals and people will give it goals to optimize towards done we're going to have it's going to have goals you'll be optimizing towards those things and when it does that you're going to have these agents that have goals that they're optimizing towards that are smart not just smarter than humans but much smarter than humans as much smarter than humans as humans were against giant sloths when we showed up in the new world and intelligence is the the uber weapon like it's not an accident that humans took over the world it's not the fastest creature it's not the strongest it's not the longest lived it's the smartest and we're going to build a new smartest species and this is a this isn't a there's no fundamentally unsolvable problem here that species could care about us like you could build into its its goals of the world how it saw the world the way humans care about other humans that it cares about the things we care about that it cares about humans that it cares about things we value the 375 different shards of human of human desire that like of everything we care about air about in the world it could care about those things too and if it does hallelujah we finally have a parent like we finally have someone who actually knows what they're doing around here because like lord knows we don't like we're we're barely competent to run this thing i would welcome very smart you know very smart other species that that is that is aligned with us and cares about us i would not welcome one that is that cares about maximizing free cash flow because that is not what humans care about and that is why it's like so dangerous and so knowing what you know then knowing what you believe first what is the probability of the bad scenario in your head are you like are we talking about a one percent uh ish thing order of magnitude 10 percent and 50 percent what is it in your in your mind i don't believe in point estimates for probabilities because it's like a bid ask spread in the market if you're really uncertain the bid ask spread doesn't clear like if you're betting on it there's just like a lot of unresolved so i think of it as a range of uncertainty and i would say that the true probability i believe is somewhere between three to thirty percent which of the downsides of the down of a very very bad thing happening which is scary enough that i urgently urge action on the issue but it's not like you should give up like probably everything's gonna be fine in fact it's probably really good the answer the the the non-ev based answer the like just the straight up like are we gonna win or not answer is like i think i think it's gonna be okay but it's such the downside is so bad it's like it's really it's like it's like probably worse than nuclear war that's a really bad downside and it's worth putting even if even if you think i'm an it's nonsense at three percent you're like no no it's no more than a half percent i you go you don't recommend a different course of action at half you have to you have to believe that it's effectively almost impossible before you would recommend ignoring it as a course as a problem like you have to be like 0.01 before be like yeah let's just roll the dice and are you gonna what are you gonna do action on that so you've kind of like you you know you're done with twitch you're in dad mode now but also this seems to be a pretty big deal yeah are you like i should do something about this or yeah i'm gonna right now i'm sort of educating myself because i think this point of view i'm starting to get in now has been developing because i like learning more about ai and i think it's one of those things we're intervening in the wrong way early it's one of those it's one of those self-fulfilling prophecy things interviewing interviewing improperly at the in the way that is not effective spends social capital and also like doesn't necessarily move the needle and i if if you didn't have people like elizabeth kowski out there banging the drum really loud i would feel more need to bang the drum myself but i feel like you're asking me the question it's you know it's out it's out in the water people know it's a problem and so i'm decided to focus my brain cycles on like what how do we actually thread the needle what is a course of action that leads us to over time eventually still being able to develop ai but also not destroying the world and i think one of the things i've gotten to is that like this idea that like oh the ai also has crystallized versus fluid intelligence just like a human does that's an important split of how to think about it and that we should be monitoring and worried about trying to understand the general intelligence not just generally benchmarking its performance on tasks because that will keep going up and is not in fact in itself necessarily intrinsically dangerous if it can't solve novel problems is there a new level is there like a better because like it hasn't passed the turing test yet but is there is there something we have after that because it seems like there's even an intelligence test i mean yeah we i mean iq tests basically like various kinds of how does it do on an iq test right now uh depends has it seen that iq test before likely has right yeah so very well on those right so what would we do how does it how does it do on novel iq tests which i don't know actually i've not seen a good benchmark though that's a good that's a good idea for something to go test yeah i think that's that's like that's the sort of thing that i think would actually be worthy of going to go do maybe there's some sort of iq test for all of the we want to put all the models through that really tries to get at fluid intelligence rather than right because you're like we have to monitor but how are we going well it's this great project arc is this group arc is working on called the evals project that's explicitly trying to build these kinds of tests they're focused on a few other more pragmatic tests right now but but i think that's the sort of thing they would go after that's a good thing i'll i'll ping paul and ask him about that you said something earlier that i want to ask you about you said founder like you know we're talking about this the singular genius that it took to figure out instagram or snapchat or right or whatever at that time and you're like you know are they lucky are they good i don't know we'll find out when they try again are you lucky are you good and are you going to try again well since i had multiple failures before i was successful i must be at least like partially lucky i would say that i don't plan to try again since i don't i don't feel drawn to trying to start a company i feel like i kind of did that it was fun i got a lot out of it it was great i don't need to do it a second time i do i like how starting a company gives me good goals and work towards it's like concrete that's a value to myself and others and i think it's also i also liked that it it was challenging and so i want to do something i like that it had scale i think i could impact a lot of people but i i sort of come around to i was sort of thinking like well what has impacted me the most what's changed my life the most and i realized that actually if i really thought about it often what it changed my life the most was like essays people had written and ideas people had shared and i think i'm at the stage of my life now where i'm i'm actually i have something to say and so i'm i i think of it as sort of trying to i want to put the emmet worldview out into the world the way that you know paul graham has put the paul graham world out in the world or taleb has like not just put his world of you out in the world but then like condensed it into like sayings that like can that allow other people to like onboard it even if they haven't read all the books and i think they have that ambition to like try to try to do the work encoded into a meme almost yeah yeah so they can be digested and shared yeah anyway you need the law you need the long form this is great blog post talking theory 201 size does matter by stevie that's about why like the people who change the world with their writing all write really long blog posts and it's basically like you just need some amount of time in someone's head to like we were talking about this earlier like to install your agent voice yeah to install the voice and so you i think i just need to produce a lot of writing and then you also need the pithy summary things which are which both are things the voice can say often in people's heads and also like enable a language for talking about your worldview that people who aren't soaking in it can like interact with so the people who are like reading you don't sound like crazy people i think that's the that's sort of what i want to work on next i love that i think that's great do you you said something about rick rubin how he's sort of the i don't know how you would describe it it's kind of like curator but almost like a collaborator really with an artist to help them do their great work is paul graham the rick rubin of the startup world no uh paul is paul is more like the um uh tony robbins of the i mean i mean in the in the in the best way it's not so much maybe not quite so much help self-help you but the main thing that talking to paul does to you repeatedly is like increase your ambition and drive like and he has good ideas sometimes too like don't get me wrong every now and then paul's a really genius idea but like mostly what i got out of talking to paul was not necessarily the great idea that would like change the trajectory of the business but the belief that i could go find it and that i was going to change the world and that i should be what we were doing was important and worth investing in and that i got a bunch of other stuff too but that was so that was singularly so valuable it like over overloads the other things i got out of it how does he do that because you know when you say that my head thinks of like a tony robbins or like a david goggins like sort of people that almost like push you but he doesn't seem like that personality and reading all of his essays he's not like that at all so how does he get you to think bigger and push harder without being a rah rah rah rah think bigger push harder right you know what you should do is the classic paul grahamism um and it's always followed by i think you could add on to what you're doing to turn it from project a addressing this small thing to project b changing the you know the universe all transportation we're going to manage power what if you've tried to power all transportation instead of like building a wheel but that's as far as you know what you should do you know what you should do is yeah yeah if you talk to paul you know i've never read what you should do you know what you should do that's that that is the consistent paulism he i don't say delude because it sounds mean but it's always like he deludes himself about your business and how great you are and invites you to join him in this deluded vision of like interpreting what you're doing in the biggest best possible light and from that vantage point what you're doing is super like what if it does what if it goes right is sort of what what he invites you to ask right what if don't stop stop asking yourself don't stop seeing all the hard problems all the you're gonna have to do ask what if what if what we're doing works what if it goes right what if it goes right and we like keep going like what could it be and when you spend time there you see how the small things can turn out to be microsoft was building programming languages for like these hobbyist microcomputers that was a tiny irrelevant market that turned out to be extremely important and that's generally true of all the big businesses but they what they start out doing the important startups they start doing something small and that seems almost trivial but there's a way in which this trivial thing can be seen bigger he sees it early no he sees he sees things that have nothing to do with the way you'll actually be big early but he sees a bunch of ways you could be big no one can do that no one actually knows if they knew it they just go do then they'd be the the the prophet the oracle what did he say let's say for justin tv or or what's up what's one we could be ready or yeah justin tv i remember one of them was like you you should like go hire all the like reality tv stars and make get them to go be on justin tv you could be you could just take over all the unscripted stuff that turns out to be just a terrible idea for a bunch of reasons but like it recontextualized what we were doing for me in terms of like we're not making a on the internet live streaming show we might be building like just the way that you make unscripted entertainment generally and that's like much bigger idea and we were making a calendar and uh for my first startup and i remember this you know what you should do is make it like programmable so that people can add in and out functionality so it can like talk to your to-do list and your your email and your like everything else in your life and then it could be your calendar in some ways like that's everything you're doing what if it was like the central hub of like your entire online information management system that's also a bad idea like your calendar shouldn't be that but like but like but a calendar could but what if it was and you walk away and and i am implicitly by saying that what he's telling you is i believe you are the kind of founders who could build an information management system that controls all the takes over people's entire like solves the entire problem for them does their takes over all their information and manages it for them you're not just like building a like google account like what what you will find out later is a google calendar clone before calendar is launched you're not just like you're not just building an outlet clone in javascript you're like changing the way people relate to information i'm like is that true it's neither true nor false that is not a true or false statement but it's a way to contextualize what you're doing it's at the it's the sonic zupari quote of like don't teach them to like carry wood or build ships teach them to yearn for the vast and endless sea like paul teaches you to see how you could be a changer of the world and how what you're doing is part of like this grand like building of the future and like the ideas i'll repeat here both of those ideas are bad but they were very helpful because they made me feel like what we were doing was important that paul believed that i could do something big and important and they caused me to even though i wound up rejecting them look for those ideas like to be open to and looking for because you would get one every like like you'd get like three an hour paul is a faucet for these it's easy i can do it for startups too now if i want to i learned the trick and i should do that more often i'm usually what fall into the tactical stuff but by by having that happen when he once he's once you've rejected 10 of those you can't help but start hearing the paul you know what you should do in your own head the ceiling has been raised yes of like what well maybe i should recontextualize my to-do list as like an email client like what why is email and to-do separate like maybe i should should be building something much bigger than what i'm building and in a way that doesn't require me to change anything maybe what i've built is already almost that if i just like think about it in a different way it's just funny balance there actually i had a a tweet thread about this recently between like you know small plans have no power to stir men's souls plan big or go home you should be really ambitious and aim super big and like only do projects that are really that you could be that you can see being being super big and super important and then the other hand the fundamental truth that like you know big trees grow from small acorns and like most of the many of the best things when they get started the person is not thinking i'm going to go take over the world they're just trying to do a good thing that like they think is good often just often for themselves even or for like a very small number of other people and then it turns out that that's much much bigger than they realized and and those are both true pieces of advice like like different people need to hear in different contexts like but they kind of contradict each other yeah what what about these other people so you've you've had a privilege i asked about paul graham you've also been friends with you were in the first yc batch so you're friends with reddit guys i think you know the colson brothers sam altman let's give me like a rapid fire on on them of like what makes them unique like you said about paul what what his kind of superpower is what really stands out what's something you admire about the way he does things give me one about maybe uh steve from reddit yeah so like it's easier in some ways with paul because like he was a mentor to me right and steve was much more like my it was like my brother in startups right growing up with paul i know i know the things that he like taught me because it was it was much more of an explicit like i was being taught by paul with steve it's like i learned things from him by like watching and imitating i think like i actually learned a lot from steve on management by watching his kind of unflappability like steve is not like an unpassionate person and like well it can get angry or it can get sad or whatever but like when there's a crisis happening or there's just i've sat i got to shadow him for a day and when bad news is delivered he responded he wasn't like moved he was like still grounded in response that to that thing and was curious asked questions like didn't jump to what to do about it but then also like ended the meeting with like all right well here's what we should do here's what we're gonna do and like it was just sort of a master class like this is this is when you when something someone brings something up it's got to be anxiety provoking it's like bad news that's what it looks like when a leader is engaged but not like not activated and like i think i in my own leadership to sometimes success and sometimes failure i think try to imitate that when i receive that you know when i have something like that in that state when you say you shattered him what was that like you guys just said hey we we exchanged like like going to each other's offices and like sitting through each like early on or like maybe like five years ago four years ago it was really cool i did with justin me justin and steve all like shadowed each other um it was pretty fun i learned a lot that's incredible to like go watch another ceo at work and like you have to have the i don't know how you have the kind of like trust relationship to make that happen without like knowing someone for 15 years uh and i happen to have the privilege to like know a bunch of ceos for a really long time and getting to go shadow each other was like a real learning thing what do you think even if these people didn't let's say explicitly teach you things you know i like you know if i read a biography or whatever one of the things i always try to figure out is more like to what extent is this person sort of built different or operates differently than like even somebody who's very good like the difference between very good and sort of like the elite what is the the best of the best at this craft versus somebody who's very good certainly very good but just not the same what is those like the diff is what i'm always most interested in i'm curious you've been around a lot of these like high-performing people even like you know yeah bezos you've you've interacted with him like do you notice any of these diffs or is it all just like it's hard it's hard to say like that i i think i believe more in contextualization like like that i see people do really amazing at something but like when it's especially when it's your own company there's a lot of like you happen to fit this problem well and it's not general i don't know how to generalize it i don't know if i don't know of anyone else even performing at this problem the ceo of stripe job is a very specific job and patrick's amazing at it would he be equally amazing at some other ceo job possibly but i've never seen him do that i've never seen anyone else be ceo of stripe and it's very hard for me to is it true at the beginning like is it true as like like startup founder of ambitious company are those are those is stripe different at that stage too or yeah no absolutely people who are really good you can sense the energy and the drive and the capability and just the pace there's like it tends to like stuff happens a lot but like usually but then not always like some problems don't actually give weight like stripe is a good example of a company that gives way to a high energy high pace thing because it's it's a simple problem at some level that has infinite details that could be right but i think like i don't know if that approach would work as well if you're trying to create open ai or anthropic where it's a research oriented organization and you kind of have to be a little more patient and forcing it's impossible and so i i really believe in like fit the different people are good at different things and like obviously someone's a plus patrick's obviously a plus at being a stripe ceo and it's just hard to tell the reason which these things are transferable we don't really know but i actually one thing did come to mind about this question in terms of like a capability that i do think is generic that i did see bezos exhibit where i was like oh that's a thing that i'm good at but he is better at that i'm better than most people but he's better than me which is we present him on twitch probably twice a year once twice a year for the first three four years i was at amazon and every time two things would happen first of all he would remember everything we told him the first meeting and i don't think he was like reviewing extensive notes someone else took because i don't know when he would have the time to do that i like i observed him going from meeting to meeting and he did not review notes i think he just remembered at least the high points and the other thing was consistently he would read our plan and he would then ask a question about why we didn't do a certain thing or give us an idea for a thing we could do that i hadn't thought of before once it's a bunch of things i had usually and then at least once which is hard to do because all you do is think about that never happens most people would be lucky to get one of those one ever let alone one a year would be great like if you did it once a year or even once every three years right he could just like you just generate them and they were and they were not all bad ideas either they were new ideas but i think i had i generate a lot of ideas to get a new idea i haven't thought thought of on a topic i've been thinking about for a decade that might even be a good idea that is like he's just really fucking smart as far as i can tell like i don't know how he does that can you say a story of one of those as like the statue of limitations passed it like this is five years ago i'm trying to remember like honestly i i don't remember the specifics anymore i just remember the like the like what the moment like because the first time i was just like oh he's smart like he's seeing twitch for the first time a lot of times smart people will have a one good idea about your business the first time they see it because they have this huge history and they're pattern matching you to some historical thing they've seen and like that combination yields one new insight but then he did it the second time remember the second i was just like what is going on this doesn't make any sense like nope i've never had that experience before ever andy does not have the new idea generation capability the same way but he does have the like remember what you told him thing which is also extremely impressive like that's that's and andy has this other thing he can do that i think there's another andy also has a it's easier for me with people i've like reported to or i've learned from andy jassy yeah yeah andy has this like ability to criticize you in a way that conveys 100 i know that you're amazing i know that your plan is good or you know like or that you're at least capable of making a really good plan i know that you're working really hard and i know that you are smart and you have a great team and we have a huge opportunity and yet somehow your results are which must i don't know what's wrong but we're in this together and we're gonna like i have your back but like i but i'm confused like why aren't the results better given how amazing you are and you feel supported like you feel like he he believes in you but but like but he's just he's you're so sad oh i'm sorry i've confused i've i'm sorry i've failed even though i clearly can succeed at this i'm gonna go i'm gonna go like fix this now and like it's almost like instead of looking at this and you he comes to your side of the table says what is this yeah like how did we wind up here like how i have failed you that i didn't say something earlier like something i don't know but like not and that can come off for some people when they do that it comes off as insincere or it comes off as like they don't think you're actually competent like how did i not catch this can come off as i don't blame you because you're clearly not good enough to have caught this like he really is how did we how did we wind up here i know that we are working together we're on the same team how did we wind up with not the results we wanted with a plan that i thought we both thought seemed good like help me understand and because it because it is genuine it's super effective at least what's effective i don't know if it's like it was super effective on me and i saw it be effective on other people as well so i know it works on some number of people right and that's another one of those things i've tried i've tried to become good at i'm not i'm not as good at it as andy is but i've certainly gotten better something something to learn from that's great love that one dude thanks for doing this i know i've been i've been bothering you to do this for a long time because i i love hearing your stories love hearing the way you think it's very different than most people i run into even here in silicon valley where you're supposed to have this kind of very unique diverse set of minds you know you're you're one of them you're one of the reasons i moved out to san francisco was to meet people like you so thanks for doing this thank you i really appreciate that yeah it's a beautiful and i really appreciate being able to come on the podcast you